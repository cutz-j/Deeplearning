{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DNN_numpy",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "qP9xKbDtVXQn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file = open(\"gdrive/My Drive/DL_study/3_week/mnist_train.csv\", \"r\") \n",
        "training_data = data_file.readlines()\n",
        "data_file.close()\n",
        "\n",
        "test_data_file = open(\"gdrive/My Drive/DL_study/3_week/mnist_test.csv\", \"r\")\n",
        "test_data = test_data_file.readlines()\n",
        "test_data_file.close()"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7USCN2yEWljD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "0d31abb0-9baf-4756-8776-b0fac4271b75"
      },
      "source": [
        "print(\"num train data : {}\".format(len(training_data)))\n",
        "print(\"num test data : {}\".format(len(test_data)))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "num train data : 60000\n",
            "num test data : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Z5CxiirVZDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a084be1f-e9bd-4a8d-db0c-f99c2daf7517"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "t = np.asfarray(training_data[0].split(\",\"))\n",
        "print(t.shape)\n",
        "n = t[1:].reshape(28,28)\n",
        "\n",
        "plt.imshow(n, cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(785,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITkeekJuYecR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96d7a799-a29f-4925-8109-ff60ba1f8f99"
      },
      "source": [
        "asd = np.array([1,2,3,4], ndmin=2)\n",
        "print(asd)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1 2 3 4]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkPNqu-NVZwE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class DeepNeuralNetwork:\n",
        "    def __init__(self, input_layers, hidden_layer_1, hidden_layer_2, hidden_layer_3, output_layers):\n",
        "        self.inputs = input_layers\n",
        "        self.hidden_1 = hidden_layer_1\n",
        "        self.hidden_2 = hidden_layer_2\n",
        "        self.hidden_3 = hidden_layer_3\n",
        "        self.outputs = output_layers\n",
        "        self.test_data = None\n",
        "\n",
        "        #weight initialized by normal distribution\n",
        "        self.w_ih = np.random.randn(self.inputs, self.hidden_1) / np.sqrt(self.inputs/2)\n",
        "        self.w_hh_12 = np.random.randn(self.hidden_1, self.hidden_2) / np.sqrt(self.hidden_1/2)\n",
        "        self.w_hh_23 = np.random.randn(self.hidden_2, self.hidden_3) / np.sqrt(self.hidden_2/2)\n",
        "        self.w_ho = np.random.randn(self.hidden_3, self.outputs) / np.sqrt(self.hidden_3/2)\n",
        "\n",
        "    def predict(self, x):\n",
        "        data = self.normalize(np.asfarray(x.split(',')))\n",
        "\n",
        "        data = data[1:]\n",
        "\n",
        "        #3 DNN_layer & softmax\n",
        "        layer_1 = self.sigmoid(np.dot(data, self.w_ih))\n",
        "        layer_2 = self.tanh(np.dot(layer_1, self.w_hh_12))\n",
        "        layer_3 = self.sigmoid(np.dot(layer_2, self.w_hh_23))\n",
        "        output = self.softmax(np.dot(layer_3, self.w_ho))\n",
        "        return output\n",
        "\n",
        "    def train(self, training_data, learning_rate, epoch):\n",
        "        for ech in range(0, epoch):\n",
        "            for i, x in enumerate(training_data):\n",
        "                target = np.array(np.zeros(self.outputs) + learning_rate, ndmin=2)\n",
        "                target[0][int(x[0])] = 1-learning_rate\n",
        "                #since training data is from csv file\n",
        "                x = self.normalize(np.asfarray(x.split(\",\")))\n",
        "\n",
        "                # feed-forward propagation\n",
        "                layer1 = self.sigmoid(np.dot(x[1:], self.w_ih))\n",
        "                layer2 = self.tanh(np.dot(layer1, self.w_hh_12))\n",
        "                layer3 = self.sigmoid(np.dot(layer2, self.w_hh_23))\n",
        "                layer4 = self.softmax(np.dot(layer3, self.w_ho))\n",
        "\n",
        "                # back propagation\n",
        "                layer4_reverse = (target - layer4)\n",
        "                layer3_reverse = layer4_reverse.dot(self.w_ho.T) * (layer3 * (1 - layer3))\n",
        "                layer2_reverse = layer3_reverse.dot(self.w_hh_23.T) * (1 - layer2) * (1 + layer2)\n",
        "                layer1_reverse = layer2_reverse.dot(self.w_hh_12.T) * (layer1 * (1 - layer1))\n",
        "\n",
        "                # weight update by using SGD\n",
        "                self.w_ho = self.w_ho + learning_rate * layer4_reverse.T.dot(np.array(layer3, ndmin=2)).T\n",
        "                self.w_hh_23 = self.w_hh_23 + learning_rate * layer3_reverse.T.dot(np.array(layer2, ndmin=2)).T\n",
        "                self.w_hh_12 = self.w_hh_12 + learning_rate * layer2_reverse.T.dot(np.array(layer1, ndmin=2)).T\n",
        "                self.w_ih = self.w_ih + learning_rate * layer1_reverse.T.dot(np.array(x[1:], ndmin=2)).T\n",
        "\n",
        "                if i % 10000 == 0 :\n",
        "                    self.print_accuracy()\n",
        "\n",
        "    def print_accuracy(self):\n",
        "        matched = 0\n",
        "\n",
        "        for x in self.test_data:\n",
        "            label = int(x[0])\n",
        "            predicted = np.argmax(self.predict(x))\n",
        "            if label == predicted :\n",
        "                matched = matched + 1\n",
        "        print('TEST accuracy : {0}'.format(matched/len(self.test_data)))\n",
        "\n",
        "    #sigmoid\n",
        "    def sigmoid(self, x):\n",
        "        return 1.0/(1.0 + np.exp(-x))\n",
        "\n",
        "    #feature scalingnormalize \n",
        "    def normalize(self, x):\n",
        "        return (x / 255.0) * 0.99 + 0.01\n",
        "    \n",
        "    #tanh\n",
        "    def tanh(self, x):\n",
        "        return (np.exp(x) - np.exp(-x))/(np.exp(x) + np.exp(-x))\n",
        "        \n",
        "    #softmax\n",
        "    def softmax(self, x):\n",
        "        e_x = np.exp(x - np.max(x))\n",
        "        return e_x / e_x.sum()"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RwRJhjrcWKI1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "81fd0459-3938-4f76-ed00-728a4165818f"
      },
      "source": [
        "network = DeepNeuralNetwork(784, 100, 100, 100, 10)\n",
        "network.test_data = test_data\n",
        "network.train(training_data, 0.01, 10)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TEST accuracy : 0.1135\n",
            "TEST accuracy : 0.8563\n",
            "TEST accuracy : 0.8776\n",
            "TEST accuracy : 0.8673\n",
            "TEST accuracy : 0.8932\n",
            "TEST accuracy : 0.9181\n",
            "TEST accuracy : 0.9162\n",
            "TEST accuracy : 0.9232\n",
            "TEST accuracy : 0.9249\n",
            "TEST accuracy : 0.8819\n",
            "TEST accuracy : 0.9247\n",
            "TEST accuracy : 0.9326\n",
            "TEST accuracy : 0.9403\n",
            "TEST accuracy : 0.9399\n",
            "TEST accuracy : 0.9358\n",
            "TEST accuracy : 0.8904\n",
            "TEST accuracy : 0.9437\n",
            "TEST accuracy : 0.9456\n",
            "TEST accuracy : 0.954\n",
            "TEST accuracy : 0.954\n",
            "TEST accuracy : 0.9488\n",
            "TEST accuracy : 0.937\n",
            "TEST accuracy : 0.9536\n",
            "TEST accuracy : 0.9528\n",
            "TEST accuracy : 0.9592\n",
            "TEST accuracy : 0.9579\n",
            "TEST accuracy : 0.9553\n",
            "TEST accuracy : 0.9477\n",
            "TEST accuracy : 0.9565\n",
            "TEST accuracy : 0.957\n",
            "TEST accuracy : 0.9588\n",
            "TEST accuracy : 0.96\n",
            "TEST accuracy : 0.9587\n",
            "TEST accuracy : 0.9541\n",
            "TEST accuracy : 0.9601\n",
            "TEST accuracy : 0.9598\n",
            "TEST accuracy : 0.9604\n",
            "TEST accuracy : 0.9632\n",
            "TEST accuracy : 0.9598\n",
            "TEST accuracy : 0.9583\n",
            "TEST accuracy : 0.9637\n",
            "TEST accuracy : 0.9608\n",
            "TEST accuracy : 0.9605\n",
            "TEST accuracy : 0.965\n",
            "TEST accuracy : 0.9604\n",
            "TEST accuracy : 0.9609\n",
            "TEST accuracy : 0.9659\n",
            "TEST accuracy : 0.9616\n",
            "TEST accuracy : 0.9616\n",
            "TEST accuracy : 0.9668\n",
            "TEST accuracy : 0.9622\n",
            "TEST accuracy : 0.9636\n",
            "TEST accuracy : 0.9665\n",
            "TEST accuracy : 0.9622\n",
            "TEST accuracy : 0.9624\n",
            "TEST accuracy : 0.9675\n",
            "TEST accuracy : 0.9636\n",
            "TEST accuracy : 0.9662\n",
            "TEST accuracy : 0.9674\n",
            "TEST accuracy : 0.963\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZjzvpBbXdhI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}