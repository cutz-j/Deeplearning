{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "FNyOV80YL8T0",
    "outputId": "16205b1f-35e8-4906-d2d2-0af8be8dad7d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from    tensorflow.keras import datasets, layers, optimizers, models\n",
    "from    tensorflow.keras import regularizers\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YWPfkbZFNGYE"
   },
   "outputs": [],
   "source": [
    "model = tf.keras.applications.vgg16.VGG16(weights=None,input_shape=(32,32,3),classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "id": "9SdDFPKkNIqJ",
    "outputId": "150f8885-5dbe-4141-b759-ad47271b34b1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading data...\n",
      "(50000, 32, 32, 3) (50000, 1) (10000, 32, 32, 3) (10000, 1)\n",
      "done.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import  os\n",
    "import  numpy as np\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # or any {'0', '1', '2'}\n",
    "\n",
    "def normalize(X_train, X_test):\n",
    "    # this function normalize inputs for zero mean and unit variance\n",
    "    # it is used when training a model.\n",
    "    # Input: training set and test set\n",
    "    # Output: normalized training set and test set according to the trianing set statistics.\n",
    "    X_train = X_train / 255.\n",
    "    X_test = X_test / 255.\n",
    "\n",
    "    mean = np.mean(X_train, axis=(0, 1, 2, 3))\n",
    "    std = np.std(X_train, axis=(0, 1, 2, 3))\n",
    "    print('mean:', mean, 'std:', std)\n",
    "    X_train = (X_train - mean) / (std + 1e-7)\n",
    "    X_test = (X_test - mean) / (std + 1e-7)\n",
    "    return X_train, X_test\n",
    "\n",
    "def prepare_cifar(x, y):\n",
    "\n",
    "    x = tf.cast(x, tf.float32)\n",
    "    y = tf.cast(y, tf.int32)\n",
    "    return x, y\n",
    "\n",
    "\n",
    "\n",
    "def compute_loss(logits, labels):\n",
    "    return tf.reduce_mean(\n",
    "      tf.nn.sparse_softmax_cross_entropy_with_logits(\n",
    "          logits=logits, labels=labels))\n",
    "\n",
    "\n",
    "tf.random.set_seed(22)\n",
    "\n",
    "print('loading data...')\n",
    "(x,y), (x_test, y_test) = datasets.cifar10.load_data()\n",
    "print(x.shape, y.shape, x_test.shape, y_test.shape)\n",
    "# x = tf.convert_to_tensor(x)\n",
    "# y = tf.convert_to_tensor(y)\n",
    "train_loader = tf.data.Dataset.from_tensor_slices((x,y))\n",
    "train_loader = train_loader.map(prepare_cifar).shuffle(50000).batch(256)\n",
    "\n",
    "test_loader = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n",
    "test_loader = test_loader.map(prepare_cifar).shuffle(10000).batch(256)\n",
    "print('done.')\n",
    "# must specify from_logits=True!\n",
    "criteon = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "\n",
    "optimizer = optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "# model = VGG16([32, 32, 3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "id": "Ou_L2YPNMDT6",
    "outputId": "a6063cae-106a-41b3-f36c-2c041c276ed9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 loss: 27.671894073486328 acc: 0.05859375\n",
      "0 80 loss: 23.923625946044922 acc: 0.27075195\n",
      "0 160 loss: 21.292884826660156 acc: 0.41020507\n",
      "test acc: 0.4682\n",
      "1 0 loss: 21.969139099121094 acc: 0.41015625\n",
      "1 80 loss: 19.95907974243164 acc: 0.49057618\n",
      "1 160 loss: 18.742429733276367 acc: 0.52958983\n",
      "test acc: 0.5567\n",
      "2 0 loss: 17.193065643310547 acc: 0.58984375\n",
      "2 80 loss: 17.104938507080078 acc: 0.5852051\n",
      "2 160 loss: 16.014442443847656 acc: 0.61152345\n",
      "test acc: 0.5578\n",
      "3 0 loss: 16.177104949951172 acc: 0.62109375\n",
      "3 80 loss: 14.964887619018555 acc: 0.65048826\n",
      "3 160 loss: 15.024389266967773 acc: 0.660498\n",
      "test acc: 0.5714\n",
      "4 0 loss: 15.086990356445312 acc: 0.66015625\n",
      "4 80 loss: 13.693796157836914 acc: 0.6942383\n",
      "4 160 loss: 13.082687377929688 acc: 0.6958496\n",
      "test acc: 0.6616\n",
      "5 0 loss: 12.787555694580078 acc: 0.75\n",
      "5 80 loss: 13.133464813232422 acc: 0.74838865\n",
      "5 160 loss: 14.494966506958008 acc: 0.7393066\n",
      "test acc: 0.6696\n",
      "6 0 loss: 12.851448059082031 acc: 0.7578125\n",
      "6 80 loss: 12.985835075378418 acc: 0.77978516\n",
      "6 160 loss: 11.740015983581543 acc: 0.7784668\n",
      "test acc: 0.6999\n",
      "7 0 loss: 9.908414840698242 acc: 0.82421875\n",
      "7 80 loss: 10.448662757873535 acc: 0.81645507\n",
      "7 160 loss: 11.154706954956055 acc: 0.81206053\n",
      "test acc: 0.6982\n",
      "8 0 loss: 11.337032318115234 acc: 0.80859375\n",
      "8 80 loss: 8.908143043518066 acc: 0.84819335\n",
      "8 160 loss: 9.555882453918457 acc: 0.8408203\n",
      "test acc: 0.7195\n",
      "9 0 loss: 7.51707649230957 acc: 0.88671875\n",
      "9 80 loss: 7.761812210083008 acc: 0.8660644\n",
      "9 160 loss: 8.579937934875488 acc: 0.8618652\n",
      "test acc: 0.6952\n",
      "10 0 loss: 10.153091430664062 acc: 0.8125\n",
      "10 80 loss: 6.754430770874023 acc: 0.8895019\n",
      "10 160 loss: 8.965683937072754 acc: 0.8821289\n",
      "test acc: 0.7106\n",
      "11 0 loss: 6.8675665855407715 acc: 0.8984375\n",
      "11 80 loss: 7.625095844268799 acc: 0.9097168\n",
      "11 160 loss: 7.097070217132568 acc: 0.8989258\n",
      "test acc: 0.7268\n",
      "12 0 loss: 5.847353935241699 acc: 0.9375\n",
      "12 80 loss: 7.104386329650879 acc: 0.91381836\n",
      "12 160 loss: 7.4506731033325195 acc: 0.9048828\n",
      "test acc: 0.6832\n",
      "13 0 loss: 8.345454216003418 acc: 0.875\n",
      "13 80 loss: 6.548442840576172 acc: 0.9218262\n",
      "13 160 loss: 6.504266262054443 acc: 0.9187012\n",
      "test acc: 0.7217\n",
      "14 0 loss: 6.359539031982422 acc: 0.92578125\n",
      "14 80 loss: 5.95781946182251 acc: 0.9307617\n",
      "14 160 loss: 5.765703201293945 acc: 0.92871094\n",
      "test acc: 0.706\n",
      "15 0 loss: 5.005476474761963 acc: 0.95703125\n",
      "15 80 loss: 6.438084602355957 acc: 0.9380859\n",
      "15 160 loss: 6.136802673339844 acc: 0.9393066\n",
      "test acc: 0.7127\n",
      "16 0 loss: 6.563244819641113 acc: 0.91015625\n",
      "16 80 loss: 5.455496788024902 acc: 0.9405762\n",
      "16 160 loss: 5.994939804077148 acc: 0.9367676\n",
      "test acc: 0.7284\n",
      "17 0 loss: 4.4443440437316895 acc: 0.96875\n",
      "17 80 loss: 4.715911388397217 acc: 0.9525879\n",
      "17 160 loss: 5.599709987640381 acc: 0.94091797\n",
      "test acc: 0.7271\n",
      "18 0 loss: 4.09011173248291 acc: 0.96875\n",
      "18 80 loss: 4.780506610870361 acc: 0.95166016\n",
      "18 160 loss: 5.188345909118652 acc: 0.94785154\n",
      "test acc: 0.7167\n",
      "19 0 loss: 5.957024574279785 acc: 0.93359375\n",
      "19 80 loss: 4.770510673522949 acc: 0.9524902\n",
      "19 160 loss: 4.652031898498535 acc: 0.946582\n",
      "test acc: 0.7267\n",
      "20 0 loss: 4.78286600112915 acc: 0.9609375\n",
      "20 80 loss: 4.663665294647217 acc: 0.95947266\n",
      "20 160 loss: 5.271897315979004 acc: 0.9511719\n",
      "test acc: 0.7191\n",
      "21 0 loss: 4.06347131729126 acc: 0.96875\n",
      "21 80 loss: 4.425031661987305 acc: 0.95874023\n",
      "21 160 loss: 4.439365386962891 acc: 0.9566406\n",
      "test acc: 0.7314\n",
      "22 0 loss: 3.981083869934082 acc: 0.9765625\n",
      "22 80 loss: 4.6730875968933105 acc: 0.96225584\n",
      "22 160 loss: 4.5804243087768555 acc: 0.96069336\n",
      "test acc: 0.7306\n",
      "23 0 loss: 4.828062057495117 acc: 0.953125\n",
      "23 80 loss: 4.0008440017700195 acc: 0.96489257\n",
      "23 160 loss: 4.590184211730957 acc: 0.9585937\n",
      "test acc: 0.7259\n",
      "24 0 loss: 4.271982192993164 acc: 0.96875\n",
      "24 80 loss: 4.756527900695801 acc: 0.96259767\n",
      "24 160 loss: 4.167396068572998 acc: 0.9559082\n",
      "test acc: 0.7289\n",
      "25 0 loss: 3.901981830596924 acc: 0.98046875\n",
      "25 80 loss: 4.465694427490234 acc: 0.96542966\n",
      "25 160 loss: 5.017821788787842 acc: 0.96308595\n",
      "test acc: 0.719\n",
      "26 0 loss: 4.936906814575195 acc: 0.953125\n",
      "26 80 loss: 5.363952159881592 acc: 0.9634277\n",
      "26 160 loss: 4.933340072631836 acc: 0.95585936\n",
      "test acc: 0.7394\n",
      "27 0 loss: 4.473874568939209 acc: 0.96484375\n",
      "27 80 loss: 4.5626373291015625 acc: 0.9675293\n",
      "27 160 loss: 3.9794912338256836 acc: 0.9652344\n",
      "test acc: 0.7253\n",
      "28 0 loss: 4.816019535064697 acc: 0.953125\n",
      "28 80 loss: 4.174685478210449 acc: 0.9692383\n",
      "28 160 loss: 4.9097185134887695 acc: 0.9641113\n",
      "test acc: 0.7251\n",
      "29 0 loss: 4.3909478187561035 acc: 0.96484375\n",
      "29 80 loss: 4.116333484649658 acc: 0.9687988\n",
      "29 160 loss: 4.453281402587891 acc: 0.96655273\n",
      "test acc: 0.7317\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    for step, (x, y) in enumerate(train_loader):\n",
    "        # [b, 1] => [b]\n",
    "        y = tf.squeeze(y, axis=1)\n",
    "        # [b, 10]\n",
    "        y = tf.one_hot(y, depth=10)\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            logits = model(x)\n",
    "            loss = criteon(y, logits)\n",
    "            loss2 = compute_loss(logits, tf.argmax(y, axis=1))\n",
    "            mse_loss = tf.reduce_sum(tf.square(y-logits))\n",
    "            # print(y.shape, logits.shape)\n",
    "            metric.update_state(y, logits)\n",
    "            loss = loss + loss2 + mse_loss*0.1\n",
    "\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "        if step % 80 == 0:\n",
    "            # for g in grads:\n",
    "            #     print(tf.norm(g).numpy())\n",
    "            print(epoch, step, 'loss:', float(loss), 'acc:', metric.result().numpy())\n",
    "            metric.reset_states()\n",
    "\n",
    "\n",
    "    if epoch % 1 == 0:\n",
    "\n",
    "        metric = tf.keras.metrics.CategoricalAccuracy()\n",
    "        for x, y in test_loader:\n",
    "            # [b, 1] => [b]\n",
    "            y = tf.squeeze(y, axis=1)\n",
    "            # [b, 10]\n",
    "            y = tf.one_hot(y, depth=10)\n",
    "\n",
    "            logits = model.predict(x)\n",
    "            # be careful, these functions can accept y as [b] without warnning.\n",
    "            metric.update_state(y, logits)\n",
    "        print('test acc:', metric.result().numpy())\n",
    "        metric.reset_states()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 935
    },
    "id": "JjLjK-ZQ4gDr",
    "outputId": "9fc00237-5736-4626-cffc-db347faf42ba"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 32, 32, 64)        1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 32, 32, 64)        36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 16, 16, 128)       147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 8, 8, 256)         590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 4, 4, 512)         1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 4, 4, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 2, 2, 512)         0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 2, 2, 512)         2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 1, 1, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              2101248   \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 10)                40970     \n",
      "=================================================================\n",
      "Total params: 33,638,218\n",
      "Trainable params: 33,638,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 주어진 VGG16모델의 첫번째 블록   \n",
    "## 두번째 convolution layer의 값을 output으로 가지는 model을 선언하시오"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "tAgOzefqoLCg"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "layer_name = 'block2_conv1'\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([32, 32, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "image_count = list(glob.glob(r'C:\\Users\\jonathan\\Desktop\\dl_study\\cifar10\\cifar10\\test\\airplane\\*.png'))\n",
    "image_count\n",
    "# list_ds = tf.data.Dataset.list_files(str(data_dir/'*/*'))\n",
    "obj =tf.io.read_file(image_count[1])\n",
    "img = tf.image.decode_jpeg(obj, channels=3)\n",
    "img = tf.image.convert_image_dtype(img, tf.float32)\n",
    "# resize the image to the desired size.\n",
    "output = tf.image.resize(img, [32, 32])\n",
    "output.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = output[np.newaxis,...]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8a1366b48>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline     \n",
    "\n",
    "refFeature = intermediate_layer_model.predict(output)\n",
    "\n",
    "plt.imshow(output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# opt = tf.keras.optimizers.Adam(learning_rate=0.01,epsilon=1e-04, amsgrad=True)\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "grad_metric = tf.keras.losses.mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "modifier = tf.Variable(np.zeros((1, 32, 32, 3)), dtype=tf.float32,trainable=True)\n",
    "for i in range(5000):\n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        tape.watch(modifier)\n",
    "        temp_output = intermediate_layer_model(modifier)\n",
    "        mse_loss = grad_metric(refFeature,temp_output)\n",
    "        # l2_loss = tf.nn.l2_loss(modifier)\n",
    "        TV_loss = tf.image.total_variation(modifier)*0.1\n",
    "        # final = mse_loss+l2_loss\n",
    "        # +\n",
    "\n",
    "\n",
    "    grads_1 = tape.gradient(mse_loss, modifier)\n",
    "  # grads_2 = tape.gradient(l2_loss, modifier)\n",
    "  # grads_3 = tape.gradient(TV_loss, modifier)\n",
    "\n",
    "\n",
    "    opt.apply_gradients(zip([grads_1], [modifier]))\n",
    "  # opt1.apply_gradients(zip([grads_2], [modifier]))\n",
    "  # opt1.apply_gradients(zip([grads_3], [modifier]))\n",
    "  # modifier.assign_sub(grads_1*0.001)\n",
    "  # modifier.assign_sub(grads_2*0.01)\n",
    "  # modifier.assign_sub(grads_3*0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f8a136ca08>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# obj= np.random.rand(32,32,3)\n",
    "# plt.imshow(modifier[0, :, :,2])\n",
    "object = tf.keras.preprocessing.image.array_to_img(\n",
    "    modifier[0, :, :,:], data_format=\"channels_last\", scale=True, dtype=None\n",
    ")\n",
    "\n",
    "plt.imshow(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "DLHW_1",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
