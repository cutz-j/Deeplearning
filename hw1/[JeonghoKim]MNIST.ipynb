{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MNIST",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8ilZy_LknuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e7ae3059-ac2c-484b-c0e1-fcccb40a69bd"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "class mnist_classifier(torch.nn.Module):\n",
        "    def __init__(self, batch_size = 256, num_classes = 10):\n",
        "        super(mnist_classifier, self).__init__()\n",
        "        self.num_classes = num_classes\n",
        "        self.batch_size = batch_size\n",
        "        self.layer0 = torch.nn.Sequential(\n",
        "                                           torch.nn.Conv2d(1, 16, 3),\n",
        "                                           torch.nn.ReLU(),\n",
        "                                           torch.nn.Conv2d(16, 32, 3),\n",
        "                                           torch.nn.ReLU(),\n",
        "                                           torch.nn.MaxPool2d(2,2),\n",
        "                                           torch.nn.Conv2d(32, 64, 3),\n",
        "                                           torch.nn.ReLU(),\n",
        "                                           torch.nn.MaxPool2d(2,2)\n",
        "                                                                \n",
        "        )\n",
        "\n",
        "        self.flatten = torch.nn.Sequential(\n",
        "                                            torch.nn.Linear(64*5*5, 100),\n",
        "                                            torch.nn.ReLU(),\n",
        "                                            torch.nn.Linear(100, self.num_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        out = self.layer0(inputs)\n",
        "        out = out.reshape(self.batch_size,-1)\n",
        "        return self.flatten(out)\n",
        "\n",
        "\n",
        "#하이퍼 파라미터 \n",
        "BATCH_SIZE = 256\n",
        "LEARNING_RATE = 0.001\n",
        "NUM_EPOCHS = 10\n",
        "\n",
        "\n",
        "#augmentation & 데이터 로드 \n",
        "transforms = torchvision.transforms.Compose([\n",
        "                                             torchvision.transforms.ToTensor()\n",
        "])\n",
        "train_datagen = torchvision.datasets.MNIST(root = \"./data\", train = True, transform = transforms, target_transform=None, download=True)\n",
        "test_datagen = torchvision.datasets.MNIST(root = \"./data\", train = False, transform = transforms, target_transform=None, download = True)\n",
        "train_loader = torch.utils.data.DataLoader(train_datagen, batch_size = BATCH_SIZE, shuffle = True, num_workers = 4, drop_last = True)\n",
        "test_loader = torch.utils.data.DataLoader(test_datagen, batch_size = BATCH_SIZE, shuffle = False, num_workers = 4, drop_last= True)\n",
        "\n",
        "\n",
        "\n",
        "#loss function & optimizer\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = mnist_classifier().to(device)\n",
        "loss_func = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)\n",
        "\n",
        "#train\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    for i , (image, label) in enumerate(train_loader):\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        logits = model.forward(image)\n",
        "        loss = loss_func(logits, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if i & 1000 ==0:\n",
        "            print(\"loss : {}\".format(loss))\n",
        "\n",
        "\n",
        "#test\n",
        "total = 0\n",
        "correct = 0\n",
        "with torch.no_grad():\n",
        "    for image, label in test_loader:\n",
        "        image = image.to(device)\n",
        "        label = label.to(device)\n",
        "\n",
        "        logits = model.forward(image)\n",
        "        _,  y_pred=torch.max(logits, 1)\n",
        "        \n",
        "        total += y_pred.shape[0]\n",
        "        correct += (label == y_pred).sum().float()\n",
        "\n",
        "\n",
        "print(\"accuracy : {}%\".format(100 * correct / total))\n",
        "        \n",
        " \n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss : 2.3034162521362305\n",
            "loss : 2.288954257965088\n",
            "loss : 2.2750258445739746\n",
            "loss : 2.2612826824188232\n",
            "loss : 2.238125801086426\n",
            "loss : 2.188901901245117\n",
            "loss : 2.1385960578918457\n",
            "loss : 2.1020667552948\n",
            "loss : 0.9626778960227966\n",
            "loss : 0.8317955136299133\n",
            "loss : 0.7459065914154053\n",
            "loss : 0.7567909955978394\n",
            "loss : 0.6365780830383301\n",
            "loss : 0.5527166724205017\n",
            "loss : 0.6185261011123657\n",
            "loss : 0.5654776096343994\n",
            "loss : 0.09019298106431961\n",
            "loss : 0.12619976699352264\n",
            "loss : 0.08495225757360458\n",
            "loss : 0.06955520808696747\n",
            "loss : 0.08536488562822342\n",
            "loss : 0.10468530654907227\n",
            "loss : 0.09387943148612976\n",
            "loss : 0.05416139215230942\n",
            "loss : 0.08150587230920792\n",
            "loss : 0.058031968772411346\n",
            "loss : 0.09686620533466339\n",
            "loss : 0.043970827013254166\n",
            "loss : 0.05175198242068291\n",
            "loss : 0.07467679679393768\n",
            "loss : 0.08703519403934479\n",
            "loss : 0.05318763107061386\n",
            "loss : 0.017171800136566162\n",
            "loss : 0.05447135120630264\n",
            "loss : 0.04932793229818344\n",
            "loss : 0.06138625368475914\n",
            "loss : 0.03853132203221321\n",
            "loss : 0.014371424913406372\n",
            "loss : 0.02728283405303955\n",
            "loss : 0.015144173055887222\n",
            "loss : 0.029386000707745552\n",
            "loss : 0.04196891933679581\n",
            "loss : 0.06158141791820526\n",
            "loss : 0.04156792536377907\n",
            "loss : 0.0350869745016098\n",
            "loss : 0.07105335593223572\n",
            "loss : 0.0266854427754879\n",
            "loss : 0.014393376186490059\n",
            "loss : 0.02662094123661518\n",
            "loss : 0.023746203631162643\n",
            "loss : 0.014512503519654274\n",
            "loss : 0.04460315778851509\n",
            "loss : 0.04272279143333435\n",
            "loss : 0.04888325184583664\n",
            "loss : 0.016976039856672287\n",
            "loss : 0.02288455329835415\n",
            "loss : 0.01390836015343666\n",
            "loss : 0.023048460483551025\n",
            "loss : 0.0390661358833313\n",
            "loss : 0.027209319174289703\n",
            "loss : 0.06130857393145561\n",
            "loss : 0.05927884951233864\n",
            "loss : 0.030992725864052773\n",
            "loss : 0.03269133344292641\n",
            "loss : 0.021902313455939293\n",
            "loss : 0.024917149916291237\n",
            "loss : 0.014185069128870964\n",
            "loss : 0.0207662470638752\n",
            "loss : 0.055949777364730835\n",
            "loss : 0.028287727385759354\n",
            "loss : 0.04791906103491783\n",
            "loss : 0.02213243581354618\n",
            "loss : 0.03021056391298771\n",
            "loss : 0.02443465031683445\n",
            "loss : 0.037219271063804626\n",
            "loss : 0.01373225450515747\n",
            "loss : 0.04019372910261154\n",
            "loss : 0.03289976343512535\n",
            "loss : 0.04684840887784958\n",
            "loss : 0.015463544055819511\n",
            "loss : 0.007568800821900368\n",
            "loss : 0.010881444439291954\n",
            "loss : 0.016521399840712547\n",
            "loss : 0.011867072433233261\n",
            "loss : 0.020324939861893654\n",
            "loss : 0.03616547957062721\n",
            "loss : 0.02954537607729435\n",
            "loss : 0.01955965720117092\n",
            "loss : 0.01551143266260624\n",
            "loss : 0.014586811885237694\n",
            "loss : 0.011197976768016815\n",
            "loss : 0.01271943747997284\n",
            "loss : 0.014895268715918064\n",
            "loss : 0.022369520738720894\n",
            "loss : 0.025865662842988968\n",
            "loss : 0.0076662227511405945\n",
            "loss : 0.005774902179837227\n",
            "loss : 0.024223636835813522\n",
            "loss : 0.003287050873041153\n",
            "loss : 0.01799006387591362\n",
            "loss : 0.01336112804710865\n",
            "loss : 0.0196332149207592\n",
            "loss : 0.01328861154615879\n",
            "loss : 0.008202329277992249\n",
            "loss : 0.019429486244916916\n",
            "loss : 0.0046365875750780106\n",
            "loss : 0.006207389757037163\n",
            "loss : 0.008333465084433556\n",
            "loss : 0.02935303933918476\n",
            "loss : 0.011631464585661888\n",
            "loss : 0.0033358484506607056\n",
            "loss : 0.07116221636533737\n",
            "loss : 0.022731387987732887\n",
            "loss : 0.03731447458267212\n",
            "loss : 0.012854529544711113\n",
            "loss : 0.001805633306503296\n",
            "loss : 0.0056558530777692795\n",
            "loss : 0.02462034299969673\n",
            "loss : 0.013372175395488739\n",
            "loss : 0.009119445458054543\n",
            "loss : 0.014200553297996521\n",
            "loss : 0.004611600190401077\n",
            "loss : 0.006903195753693581\n",
            "loss : 0.01444282941520214\n",
            "loss : 0.017350830137729645\n",
            "loss : 0.007809527218341827\n",
            "loss : 0.013519162312150002\n",
            "loss : 0.011133769527077675\n",
            "loss : 0.013684112578630447\n",
            "loss : 0.004939019680023193\n",
            "loss : 0.004683220759034157\n",
            "loss : 0.007229035720229149\n",
            "loss : 0.02132709138095379\n",
            "loss : 0.017821049317717552\n",
            "loss : 0.00953696295619011\n",
            "loss : 0.016960768029093742\n",
            "loss : 0.004141073673963547\n",
            "loss : 0.012850720435380936\n",
            "loss : 0.01345473900437355\n",
            "loss : 0.025026194751262665\n",
            "loss : 0.004941379651427269\n",
            "loss : 0.0033202432096004486\n",
            "loss : 0.008249131962656975\n",
            "loss : 0.008362330496311188\n",
            "loss : 0.004129335284233093\n",
            "loss : 0.004129689186811447\n",
            "loss : 0.010117623955011368\n",
            "loss : 0.02792838215827942\n",
            "loss : 0.007549777626991272\n",
            "loss : 0.01878683641552925\n",
            "loss : 0.005351301282644272\n",
            "loss : 0.006111282855272293\n",
            "loss : 0.0032577775418758392\n",
            "loss : 0.00824618712067604\n",
            "loss : 0.001850087195634842\n",
            "loss : 0.00787166878581047\n",
            "loss : 0.012871116399765015\n",
            "loss : 0.02266591042280197\n",
            "loss : 0.003282751888036728\n",
            "loss : 0.026362132281064987\n",
            "accuracy : 99.20873260498047%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NwfwJD1M3F-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aavdqSXxOc88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}