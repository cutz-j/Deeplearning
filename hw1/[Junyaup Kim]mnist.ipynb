{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST \n",
    "## 1. as a image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn,functional\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0      1       0       0       0       0       0       0       0       0   \n",
       "1      0       0       0       0       0       0       0       0       0   \n",
       "2      1       0       0       0       0       0       0       0       0   \n",
       "3      4       0       0       0       0       0       0       0       0   \n",
       "4      0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "   pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0       0  ...         0         0         0         0         0         0   \n",
       "1       0  ...         0         0         0         0         0         0   \n",
       "2       0  ...         0         0         0         0         0         0   \n",
       "3       0  ...         0         0         0         0         0         0   \n",
       "4       0  ...         0         0         0         0         0         0   \n",
       "\n",
       "   pixel780  pixel781  pixel782  pixel783  \n",
       "0         0         0         0         0  \n",
       "1         0         0         0         0  \n",
       "2         0         0         0         0  \n",
       "3         0         0         0         0  \n",
       "4         0         0         0         0  \n",
       "\n",
       "[5 rows x 785 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(1) # seed\n",
    "df_train = pd.read_csv(r\"./mnist_as_csv/train.csv\") \n",
    "df_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_train.loc[:,df_train.columns !=\"label\"]\n",
    "Y = df_train.loc[:,df_train.columns ==\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X/255\n",
    "X =X.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE =16\n",
    "\n",
    "X_train = torch.from_numpy(x_train)\n",
    "X_test = torch.from_numpy(x_test)\n",
    "\n",
    "Y_train = torch.from_numpy(y_train).type(torch.LongTensor) \n",
    "Y_test = torch.from_numpy(y_test).type(torch.LongTensor)\n",
    "\n",
    "train = torch.utils.data.TensorDataset(X_train,Y_train)\n",
    "test = torch.utils.data.TensorDataset(X_test,Y_test)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size = BATCH_SIZE, shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size = BATCH_SIZE, shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN,self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNN_drop(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DNN_drop,self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.dropout= nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.fc3 = nn.Linear(64, 10)\n",
    "        self.relu= nn.ReLU()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc3(x)\n",
    "        \n",
    "        \n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = 1, out_channels = 6, kernel_size = 2)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.fc1 = nn.Linear(4374, 128) \n",
    "        self.fc2 = nn.Linear(128, 64) \n",
    "        self.out = nn.Linear(64, 10) \n",
    "        \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.conv(x)\n",
    "        out = self.relu(out)\n",
    "        \n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.out(out)\n",
    "        \n",
    "        return F.log_softmax(out, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model_1 = DNN().to(device)\n",
    "model_2 = DNN_drop().to(device)\n",
    "model_3 = CNN().to(device)\n",
    "# model_1=model_1.double()\n",
    "# model_2=model_2.double()\n",
    "# model_3=model_3.double()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1, 128]              100,480\n",
      "├─ReLU: 1-2                              [-1, 1, 128]              --\n",
      "├─Linear: 1-3                            [-1, 1, 64]               8,256\n",
      "├─ReLU: 1-4                              [-1, 1, 64]               --\n",
      "├─Linear: 1-5                            [-1, 1, 10]               650\n",
      "==========================================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.11\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.42\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 1, 128]              100,480\n",
       "├─ReLU: 1-2                              [-1, 1, 128]              --\n",
       "├─Linear: 1-3                            [-1, 1, 64]               8,256\n",
       "├─ReLU: 1-4                              [-1, 1, 64]               --\n",
       "├─Linear: 1-5                            [-1, 1, 10]               650\n",
       "==========================================================================================\n",
       "Total params: 109,386\n",
       "Trainable params: 109,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.11\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.42\n",
       "Estimated Total Size (MB): 0.42\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_1, (1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Linear: 1-1                            [-1, 1, 128]              100,480\n",
      "├─ReLU: 1-2                              [-1, 1, 128]              --\n",
      "├─Dropout: 1-3                           [-1, 1, 128]              --\n",
      "├─Linear: 1-4                            [-1, 1, 64]               8,256\n",
      "├─ReLU: 1-5                              [-1, 1, 64]               --\n",
      "├─Linear: 1-6                            [-1, 1, 10]               650\n",
      "==========================================================================================\n",
      "Total params: 109,386\n",
      "Trainable params: 109,386\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.11\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.42\n",
      "Estimated Total Size (MB): 0.42\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Linear: 1-1                            [-1, 1, 128]              100,480\n",
       "├─ReLU: 1-2                              [-1, 1, 128]              --\n",
       "├─Dropout: 1-3                           [-1, 1, 128]              --\n",
       "├─Linear: 1-4                            [-1, 1, 64]               8,256\n",
       "├─ReLU: 1-5                              [-1, 1, 64]               --\n",
       "├─Linear: 1-6                            [-1, 1, 10]               650\n",
       "==========================================================================================\n",
       "Total params: 109,386\n",
       "Trainable params: 109,386\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.11\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.00\n",
       "Params size (MB): 0.42\n",
       "Estimated Total Size (MB): 0.42\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_2, (1, 28*28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------------------------------------\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "├─Conv2d: 1-1                            [-1, 6, 27, 27]           30\n",
      "├─ReLU: 1-2                              [-1, 6, 27, 27]           --\n",
      "├─Linear: 1-3                            [-1, 128]                 560,000\n",
      "├─Linear: 1-4                            [-1, 64]                  8,256\n",
      "├─Linear: 1-5                            [-1, 10]                  650\n",
      "==========================================================================================\n",
      "Total params: 568,936\n",
      "Trainable params: 568,936\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (M): 0.59\n",
      "------------------------------------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.03\n",
      "Params size (MB): 2.17\n",
      "Estimated Total Size (MB): 2.21\n",
      "------------------------------------------------------------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "------------------------------------------------------------------------------------------\n",
       "Layer (type:depth-idx)                   Output Shape              Param #\n",
       "==========================================================================================\n",
       "├─Conv2d: 1-1                            [-1, 6, 27, 27]           30\n",
       "├─ReLU: 1-2                              [-1, 6, 27, 27]           --\n",
       "├─Linear: 1-3                            [-1, 128]                 560,000\n",
       "├─Linear: 1-4                            [-1, 64]                  8,256\n",
       "├─Linear: 1-5                            [-1, 10]                  650\n",
       "==========================================================================================\n",
       "Total params: 568,936\n",
       "Trainable params: 568,936\n",
       "Non-trainable params: 0\n",
       "Total mult-adds (M): 0.59\n",
       "------------------------------------------------------------------------------------------\n",
       "Input size (MB): 0.00\n",
       "Forward/backward pass size (MB): 0.03\n",
       "Params size (MB): 2.17\n",
       "Estimated Total Size (MB): 2.21\n",
       "------------------------------------------------------------------------------------------"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary(model_3, (1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion =   nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_1.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### custom dataset과 image folder를 활용해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MNIST_CSV(Dataset):\n",
    "#     def __init__(self, csv_file, transform=None):\n",
    "\n",
    "#         self.mnist = pd.read_csv(csv_file)\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.mnist)\n",
    "\n",
    "#     def __getitem__(self, idx):\n",
    "#         sample = self.mnist[idx]\n",
    "\n",
    "#         if self.transform:\n",
    "#             sample = self.transform(sample)\n",
    "\n",
    "#         return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ImageFolder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-50e26fab6309>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# from torchvision.datasets import ImageFolder\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# #dataset 먼저 선언 후 loader에 맵핑\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtrain_dataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImageFolder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'./mnist_as_image'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mtrain_loader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_workers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ImageFolder' is not defined"
     ]
    }
   ],
   "source": [
    "# from torchvision.datasets import ImageFolder \n",
    "# # #dataset 먼저 선언 후 loader에 맵핑\n",
    "# train_dataset = ImageFolder(root='./mnist_as_image', transform=None) \n",
    "# train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## without dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 94.85714285714286 %\n",
      "Accuracy of the network on the 10000 test images: 96.41666666666667 %\n",
      "Accuracy of the network on the 10000 test images: 96.38095238095238 %\n",
      "Accuracy of the network on the 10000 test images: 97.20238095238095 %\n",
      "Accuracy of the network on the 10000 test images: 96.61904761904762 %\n",
      "Accuracy of the network on the 10000 test images: 96.97619047619048 %\n",
      "Accuracy of the network on the 10000 test images: 97.32142857142857 %\n",
      "Accuracy of the network on the 10000 test images: 97.05952380952381 %\n",
      "Accuracy of the network on the 10000 test images: 97.36904761904762 %\n",
      "Accuracy of the network on the 10000 test images: 97.26190476190476 %\n",
      "Accuracy of the network on the 10000 test images: 96.94047619047619 %\n",
      "Accuracy of the network on the 10000 test images: 97.38095238095238 %\n",
      "Accuracy of the network on the 10000 test images: 97.27380952380952 %\n",
      "Accuracy of the network on the 10000 test images: 96.80952380952381 %\n",
      "Accuracy of the network on the 10000 test images: 97.28571428571429 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(15):\n",
    "    model_1.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_1(images)\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        \n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model_1.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(1)\n",
    "            outputs = model_1(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model_2.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## with dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 95.0952380952381 %\n",
      "Accuracy of the network on the 10000 test images: 96.08333333333333 %\n",
      "Accuracy of the network on the 10000 test images: 96.57142857142857 %\n",
      "Accuracy of the network on the 10000 test images: 96.76190476190476 %\n",
      "Accuracy of the network on the 10000 test images: 96.85714285714286 %\n",
      "Accuracy of the network on the 10000 test images: 96.66666666666667 %\n",
      "Accuracy of the network on the 10000 test images: 97.08333333333333 %\n",
      "Accuracy of the network on the 10000 test images: 97.32142857142857 %\n",
      "Accuracy of the network on the 10000 test images: 97.28571428571429 %\n",
      "Accuracy of the network on the 10000 test images: 97.08333333333333 %\n",
      "Accuracy of the network on the 10000 test images: 97.58333333333333 %\n",
      "Accuracy of the network on the 10000 test images: 96.9047619047619 %\n",
      "Accuracy of the network on the 10000 test images: 97.58333333333333 %\n",
      "Accuracy of the network on the 10000 test images: 97.4047619047619 %\n",
      "Accuracy of the network on the 10000 test images: 97.11904761904762 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(15):\n",
    "    model_2.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "    \n",
    "        images = images.to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_2(images)\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "#         print(\"loss is :%f\" % loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model_2.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(1)\n",
    "            outputs = model_2(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion =   nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model_3.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/15], Step [100/2100], Loss: 0.3657\n",
      "Epoch [1/15], Step [200/2100], Loss: 0.4869\n",
      "Epoch [1/15], Step [300/2100], Loss: 0.0685\n",
      "Epoch [1/15], Step [400/2100], Loss: 0.3513\n",
      "Epoch [1/15], Step [500/2100], Loss: 0.4647\n",
      "Epoch [1/15], Step [600/2100], Loss: 0.6733\n",
      "Epoch [1/15], Step [700/2100], Loss: 0.4573\n",
      "Epoch [1/15], Step [800/2100], Loss: 0.3677\n",
      "Epoch [1/15], Step [900/2100], Loss: 0.4958\n",
      "Epoch [1/15], Step [1000/2100], Loss: 0.2925\n",
      "Epoch [1/15], Step [1100/2100], Loss: 0.3718\n",
      "Epoch [1/15], Step [1200/2100], Loss: 0.5895\n",
      "Epoch [1/15], Step [1300/2100], Loss: 0.0935\n",
      "Epoch [1/15], Step [1400/2100], Loss: 0.6530\n",
      "Epoch [1/15], Step [1500/2100], Loss: 0.1517\n",
      "Epoch [1/15], Step [1600/2100], Loss: 0.4574\n",
      "Epoch [1/15], Step [1700/2100], Loss: 0.5392\n",
      "Epoch [1/15], Step [1800/2100], Loss: 0.0719\n",
      "Epoch [1/15], Step [1900/2100], Loss: 0.2225\n",
      "Epoch [1/15], Step [2000/2100], Loss: 0.1269\n",
      "Epoch [1/15], Step [2100/2100], Loss: 0.1783\n",
      "Accuracy of the network on the 10000 test images: 91.5 %\n",
      "Epoch [2/15], Step [100/2100], Loss: 0.4860\n",
      "Epoch [2/15], Step [200/2100], Loss: 0.4421\n",
      "Epoch [2/15], Step [300/2100], Loss: 0.1165\n",
      "Epoch [2/15], Step [400/2100], Loss: 0.0271\n",
      "Epoch [2/15], Step [500/2100], Loss: 0.0774\n",
      "Epoch [2/15], Step [600/2100], Loss: 0.3133\n",
      "Epoch [2/15], Step [700/2100], Loss: 0.2870\n",
      "Epoch [2/15], Step [800/2100], Loss: 0.0949\n",
      "Epoch [2/15], Step [900/2100], Loss: 0.1741\n",
      "Epoch [2/15], Step [1000/2100], Loss: 0.2325\n",
      "Epoch [2/15], Step [1100/2100], Loss: 0.1238\n",
      "Epoch [2/15], Step [1200/2100], Loss: 0.1504\n",
      "Epoch [2/15], Step [1300/2100], Loss: 0.2544\n",
      "Epoch [2/15], Step [1400/2100], Loss: 0.0447\n",
      "Epoch [2/15], Step [1500/2100], Loss: 0.0128\n",
      "Epoch [2/15], Step [1600/2100], Loss: 0.4023\n",
      "Epoch [2/15], Step [1700/2100], Loss: 0.2120\n",
      "Epoch [2/15], Step [1800/2100], Loss: 0.1880\n",
      "Epoch [2/15], Step [1900/2100], Loss: 0.0908\n",
      "Epoch [2/15], Step [2000/2100], Loss: 0.2073\n",
      "Epoch [2/15], Step [2100/2100], Loss: 0.2182\n",
      "Accuracy of the network on the 10000 test images: 95.32142857142857 %\n",
      "Epoch [3/15], Step [100/2100], Loss: 0.3629\n",
      "Epoch [3/15], Step [200/2100], Loss: 0.4036\n",
      "Epoch [3/15], Step [300/2100], Loss: 0.1967\n",
      "Epoch [3/15], Step [400/2100], Loss: 0.0395\n",
      "Epoch [3/15], Step [500/2100], Loss: 0.0359\n",
      "Epoch [3/15], Step [600/2100], Loss: 0.1507\n",
      "Epoch [3/15], Step [700/2100], Loss: 0.0191\n",
      "Epoch [3/15], Step [800/2100], Loss: 0.2071\n",
      "Epoch [3/15], Step [900/2100], Loss: 0.0279\n",
      "Epoch [3/15], Step [1000/2100], Loss: 0.3464\n",
      "Epoch [3/15], Step [1100/2100], Loss: 0.1526\n",
      "Epoch [3/15], Step [1200/2100], Loss: 0.0076\n",
      "Epoch [3/15], Step [1300/2100], Loss: 0.1629\n",
      "Epoch [3/15], Step [1400/2100], Loss: 0.0204\n",
      "Epoch [3/15], Step [1500/2100], Loss: 0.0605\n",
      "Epoch [3/15], Step [1600/2100], Loss: 0.1290\n",
      "Epoch [3/15], Step [1700/2100], Loss: 0.0134\n",
      "Epoch [3/15], Step [1800/2100], Loss: 0.3843\n",
      "Epoch [3/15], Step [1900/2100], Loss: 0.0711\n",
      "Epoch [3/15], Step [2000/2100], Loss: 0.1089\n",
      "Epoch [3/15], Step [2100/2100], Loss: 0.0362\n",
      "Accuracy of the network on the 10000 test images: 95.91666666666667 %\n",
      "Epoch [4/15], Step [100/2100], Loss: 0.1608\n",
      "Epoch [4/15], Step [200/2100], Loss: 0.0100\n",
      "Epoch [4/15], Step [300/2100], Loss: 0.0031\n",
      "Epoch [4/15], Step [400/2100], Loss: 0.0108\n",
      "Epoch [4/15], Step [500/2100], Loss: 0.2382\n",
      "Epoch [4/15], Step [600/2100], Loss: 0.1099\n",
      "Epoch [4/15], Step [700/2100], Loss: 0.0673\n",
      "Epoch [4/15], Step [800/2100], Loss: 0.0067\n",
      "Epoch [4/15], Step [900/2100], Loss: 0.0283\n",
      "Epoch [4/15], Step [1000/2100], Loss: 0.0226\n",
      "Epoch [4/15], Step [1100/2100], Loss: 0.0126\n",
      "Epoch [4/15], Step [1200/2100], Loss: 0.1135\n",
      "Epoch [4/15], Step [1300/2100], Loss: 0.0331\n",
      "Epoch [4/15], Step [1400/2100], Loss: 0.0025\n",
      "Epoch [4/15], Step [1500/2100], Loss: 0.0028\n",
      "Epoch [4/15], Step [1600/2100], Loss: 0.0028\n",
      "Epoch [4/15], Step [1700/2100], Loss: 0.1562\n",
      "Epoch [4/15], Step [1800/2100], Loss: 0.1603\n",
      "Epoch [4/15], Step [1900/2100], Loss: 0.0035\n",
      "Epoch [4/15], Step [2000/2100], Loss: 0.0406\n",
      "Epoch [4/15], Step [2100/2100], Loss: 0.0214\n",
      "Accuracy of the network on the 10000 test images: 96.0 %\n",
      "Epoch [5/15], Step [100/2100], Loss: 0.0094\n",
      "Epoch [5/15], Step [200/2100], Loss: 0.0134\n",
      "Epoch [5/15], Step [300/2100], Loss: 0.0107\n",
      "Epoch [5/15], Step [400/2100], Loss: 0.0039\n",
      "Epoch [5/15], Step [500/2100], Loss: 0.0578\n",
      "Epoch [5/15], Step [600/2100], Loss: 0.0513\n",
      "Epoch [5/15], Step [700/2100], Loss: 0.0574\n",
      "Epoch [5/15], Step [800/2100], Loss: 0.0326\n",
      "Epoch [5/15], Step [900/2100], Loss: 0.0054\n",
      "Epoch [5/15], Step [1000/2100], Loss: 0.1644\n",
      "Epoch [5/15], Step [1100/2100], Loss: 0.0344\n",
      "Epoch [5/15], Step [1200/2100], Loss: 0.0325\n",
      "Epoch [5/15], Step [1300/2100], Loss: 0.0013\n",
      "Epoch [5/15], Step [1400/2100], Loss: 0.0441\n",
      "Epoch [5/15], Step [1500/2100], Loss: 0.0864\n",
      "Epoch [5/15], Step [1600/2100], Loss: 0.2839\n",
      "Epoch [5/15], Step [1700/2100], Loss: 0.0218\n",
      "Epoch [5/15], Step [1800/2100], Loss: 0.0317\n",
      "Epoch [5/15], Step [1900/2100], Loss: 0.0023\n",
      "Epoch [5/15], Step [2000/2100], Loss: 0.0144\n",
      "Epoch [5/15], Step [2100/2100], Loss: 0.2010\n",
      "Accuracy of the network on the 10000 test images: 96.63095238095238 %\n",
      "Epoch [6/15], Step [100/2100], Loss: 0.0002\n",
      "Epoch [6/15], Step [200/2100], Loss: 0.2958\n",
      "Epoch [6/15], Step [300/2100], Loss: 0.0029\n",
      "Epoch [6/15], Step [400/2100], Loss: 0.1738\n",
      "Epoch [6/15], Step [500/2100], Loss: 0.0004\n",
      "Epoch [6/15], Step [600/2100], Loss: 0.0869\n",
      "Epoch [6/15], Step [700/2100], Loss: 0.0176\n",
      "Epoch [6/15], Step [800/2100], Loss: 0.1374\n",
      "Epoch [6/15], Step [900/2100], Loss: 0.0003\n",
      "Epoch [6/15], Step [1000/2100], Loss: 0.0091\n",
      "Epoch [6/15], Step [1100/2100], Loss: 0.0011\n",
      "Epoch [6/15], Step [1200/2100], Loss: 0.0022\n",
      "Epoch [6/15], Step [1300/2100], Loss: 0.1427\n",
      "Epoch [6/15], Step [1400/2100], Loss: 0.0060\n",
      "Epoch [6/15], Step [1500/2100], Loss: 0.0158\n",
      "Epoch [6/15], Step [1600/2100], Loss: 0.0100\n",
      "Epoch [6/15], Step [1700/2100], Loss: 0.5360\n",
      "Epoch [6/15], Step [1800/2100], Loss: 0.0022\n",
      "Epoch [6/15], Step [1900/2100], Loss: 0.3529\n",
      "Epoch [6/15], Step [2000/2100], Loss: 0.2575\n",
      "Epoch [6/15], Step [2100/2100], Loss: 0.0091\n",
      "Accuracy of the network on the 10000 test images: 96.22619047619048 %\n",
      "Epoch [7/15], Step [100/2100], Loss: 0.0342\n",
      "Epoch [7/15], Step [200/2100], Loss: 0.2851\n",
      "Epoch [7/15], Step [300/2100], Loss: 0.0006\n",
      "Epoch [7/15], Step [400/2100], Loss: 0.0527\n",
      "Epoch [7/15], Step [500/2100], Loss: 0.0067\n",
      "Epoch [7/15], Step [600/2100], Loss: 0.0008\n",
      "Epoch [7/15], Step [700/2100], Loss: 0.0001\n",
      "Epoch [7/15], Step [800/2100], Loss: 0.0368\n",
      "Epoch [7/15], Step [900/2100], Loss: 0.0168\n",
      "Epoch [7/15], Step [1000/2100], Loss: 0.0099\n",
      "Epoch [7/15], Step [1100/2100], Loss: 0.0208\n",
      "Epoch [7/15], Step [1200/2100], Loss: 0.0775\n",
      "Epoch [7/15], Step [1300/2100], Loss: 0.0027\n",
      "Epoch [7/15], Step [1400/2100], Loss: 0.1372\n",
      "Epoch [7/15], Step [1500/2100], Loss: 0.0144\n",
      "Epoch [7/15], Step [1600/2100], Loss: 0.0002\n",
      "Epoch [7/15], Step [1700/2100], Loss: 0.0001\n",
      "Epoch [7/15], Step [1800/2100], Loss: 0.0106\n",
      "Epoch [7/15], Step [1900/2100], Loss: 0.0973\n",
      "Epoch [7/15], Step [2000/2100], Loss: 0.0043\n",
      "Epoch [7/15], Step [2100/2100], Loss: 0.0005\n",
      "Accuracy of the network on the 10000 test images: 96.39285714285714 %\n",
      "Epoch [8/15], Step [100/2100], Loss: 0.0049\n",
      "Epoch [8/15], Step [200/2100], Loss: 0.0968\n",
      "Epoch [8/15], Step [300/2100], Loss: 0.0138\n",
      "Epoch [8/15], Step [400/2100], Loss: 0.0004\n",
      "Epoch [8/15], Step [500/2100], Loss: 0.0123\n",
      "Epoch [8/15], Step [600/2100], Loss: 0.0001\n",
      "Epoch [8/15], Step [700/2100], Loss: 0.0002\n",
      "Epoch [8/15], Step [800/2100], Loss: 0.0550\n",
      "Epoch [8/15], Step [900/2100], Loss: 0.0009\n",
      "Epoch [8/15], Step [1000/2100], Loss: 0.1985\n",
      "Epoch [8/15], Step [1100/2100], Loss: 0.0085\n",
      "Epoch [8/15], Step [1200/2100], Loss: 0.0060\n",
      "Epoch [8/15], Step [1300/2100], Loss: 0.0096\n",
      "Epoch [8/15], Step [1400/2100], Loss: 0.0010\n",
      "Epoch [8/15], Step [1500/2100], Loss: 0.0561\n",
      "Epoch [8/15], Step [1600/2100], Loss: 0.0002\n",
      "Epoch [8/15], Step [1700/2100], Loss: 0.0019\n",
      "Epoch [8/15], Step [1800/2100], Loss: 0.0467\n",
      "Epoch [8/15], Step [1900/2100], Loss: 0.1516\n",
      "Epoch [8/15], Step [2000/2100], Loss: 0.0055\n",
      "Epoch [8/15], Step [2100/2100], Loss: 0.0004\n",
      "Accuracy of the network on the 10000 test images: 96.28571428571429 %\n",
      "Epoch [9/15], Step [100/2100], Loss: 0.0001\n",
      "Epoch [9/15], Step [200/2100], Loss: 0.0130\n",
      "Epoch [9/15], Step [300/2100], Loss: 0.0060\n",
      "Epoch [9/15], Step [400/2100], Loss: 0.0240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/15], Step [500/2100], Loss: 0.0028\n",
      "Epoch [9/15], Step [600/2100], Loss: 0.0713\n",
      "Epoch [9/15], Step [700/2100], Loss: 0.0133\n",
      "Epoch [9/15], Step [800/2100], Loss: 0.0373\n",
      "Epoch [9/15], Step [900/2100], Loss: 0.0076\n",
      "Epoch [9/15], Step [1000/2100], Loss: 0.0128\n",
      "Epoch [9/15], Step [1100/2100], Loss: 0.0000\n",
      "Epoch [9/15], Step [1200/2100], Loss: 0.3567\n",
      "Epoch [9/15], Step [1300/2100], Loss: 0.0041\n",
      "Epoch [9/15], Step [1400/2100], Loss: 0.0010\n",
      "Epoch [9/15], Step [1500/2100], Loss: 0.0082\n",
      "Epoch [9/15], Step [1600/2100], Loss: 0.0014\n",
      "Epoch [9/15], Step [1700/2100], Loss: 0.0027\n",
      "Epoch [9/15], Step [1800/2100], Loss: 0.2691\n",
      "Epoch [9/15], Step [1900/2100], Loss: 0.1979\n",
      "Epoch [9/15], Step [2000/2100], Loss: 0.0080\n",
      "Epoch [9/15], Step [2100/2100], Loss: 0.0083\n",
      "Accuracy of the network on the 10000 test images: 96.16666666666667 %\n",
      "Epoch [10/15], Step [100/2100], Loss: 0.0162\n",
      "Epoch [10/15], Step [200/2100], Loss: 0.0068\n",
      "Epoch [10/15], Step [300/2100], Loss: 0.2289\n",
      "Epoch [10/15], Step [400/2100], Loss: 0.0006\n",
      "Epoch [10/15], Step [500/2100], Loss: 0.0078\n",
      "Epoch [10/15], Step [600/2100], Loss: 0.0001\n",
      "Epoch [10/15], Step [700/2100], Loss: 0.0002\n",
      "Epoch [10/15], Step [800/2100], Loss: 0.0093\n",
      "Epoch [10/15], Step [900/2100], Loss: 0.0001\n",
      "Epoch [10/15], Step [1000/2100], Loss: 0.0007\n",
      "Epoch [10/15], Step [1100/2100], Loss: 0.0012\n",
      "Epoch [10/15], Step [1200/2100], Loss: 0.0001\n",
      "Epoch [10/15], Step [1300/2100], Loss: 0.0000\n",
      "Epoch [10/15], Step [1400/2100], Loss: 0.0038\n",
      "Epoch [10/15], Step [1500/2100], Loss: 0.1811\n",
      "Epoch [10/15], Step [1600/2100], Loss: 0.0364\n",
      "Epoch [10/15], Step [1700/2100], Loss: 0.0071\n",
      "Epoch [10/15], Step [1800/2100], Loss: 0.0001\n",
      "Epoch [10/15], Step [1900/2100], Loss: 0.0065\n",
      "Epoch [10/15], Step [2000/2100], Loss: 0.0016\n",
      "Epoch [10/15], Step [2100/2100], Loss: 0.0302\n",
      "Accuracy of the network on the 10000 test images: 96.30952380952381 %\n",
      "Epoch [11/15], Step [100/2100], Loss: 0.0026\n",
      "Epoch [11/15], Step [200/2100], Loss: 0.0025\n",
      "Epoch [11/15], Step [300/2100], Loss: 0.0001\n",
      "Epoch [11/15], Step [400/2100], Loss: 0.0068\n",
      "Epoch [11/15], Step [500/2100], Loss: 0.0000\n",
      "Epoch [11/15], Step [600/2100], Loss: 0.0014\n",
      "Epoch [11/15], Step [700/2100], Loss: 0.4599\n",
      "Epoch [11/15], Step [800/2100], Loss: 0.0042\n",
      "Epoch [11/15], Step [900/2100], Loss: 0.0014\n",
      "Epoch [11/15], Step [1000/2100], Loss: 0.0010\n",
      "Epoch [11/15], Step [1100/2100], Loss: 0.0002\n",
      "Epoch [11/15], Step [1200/2100], Loss: 0.0006\n",
      "Epoch [11/15], Step [1300/2100], Loss: 0.0001\n",
      "Epoch [11/15], Step [1400/2100], Loss: 0.0014\n",
      "Epoch [11/15], Step [1500/2100], Loss: 0.0030\n",
      "Epoch [11/15], Step [1600/2100], Loss: 0.1870\n",
      "Epoch [11/15], Step [1700/2100], Loss: 0.0001\n",
      "Epoch [11/15], Step [1800/2100], Loss: 0.0042\n",
      "Epoch [11/15], Step [1900/2100], Loss: 0.0009\n",
      "Epoch [11/15], Step [2000/2100], Loss: 0.0003\n",
      "Epoch [11/15], Step [2100/2100], Loss: 0.0005\n",
      "Accuracy of the network on the 10000 test images: 96.61904761904762 %\n",
      "Epoch [12/15], Step [100/2100], Loss: 0.0005\n",
      "Epoch [12/15], Step [200/2100], Loss: 0.0001\n",
      "Epoch [12/15], Step [300/2100], Loss: 0.0000\n",
      "Epoch [12/15], Step [400/2100], Loss: 0.0008\n",
      "Epoch [12/15], Step [500/2100], Loss: 0.0050\n",
      "Epoch [12/15], Step [600/2100], Loss: 0.0087\n",
      "Epoch [12/15], Step [700/2100], Loss: 0.0109\n",
      "Epoch [12/15], Step [800/2100], Loss: 0.0234\n",
      "Epoch [12/15], Step [900/2100], Loss: 0.0007\n",
      "Epoch [12/15], Step [1000/2100], Loss: 0.5382\n",
      "Epoch [12/15], Step [1100/2100], Loss: 0.0007\n",
      "Epoch [12/15], Step [1200/2100], Loss: 0.0001\n",
      "Epoch [12/15], Step [1300/2100], Loss: 0.0063\n",
      "Epoch [12/15], Step [1400/2100], Loss: 0.3099\n",
      "Epoch [12/15], Step [1500/2100], Loss: 0.0146\n",
      "Epoch [12/15], Step [1600/2100], Loss: 0.0000\n",
      "Epoch [12/15], Step [1700/2100], Loss: 0.0017\n",
      "Epoch [12/15], Step [1800/2100], Loss: 0.0001\n",
      "Epoch [12/15], Step [1900/2100], Loss: 0.0027\n",
      "Epoch [12/15], Step [2000/2100], Loss: 0.0000\n",
      "Epoch [12/15], Step [2100/2100], Loss: 0.0008\n",
      "Accuracy of the network on the 10000 test images: 96.46428571428571 %\n",
      "Epoch [13/15], Step [100/2100], Loss: 0.0001\n",
      "Epoch [13/15], Step [200/2100], Loss: 0.0223\n",
      "Epoch [13/15], Step [300/2100], Loss: 0.0012\n",
      "Epoch [13/15], Step [400/2100], Loss: 0.0000\n",
      "Epoch [13/15], Step [500/2100], Loss: 0.0011\n",
      "Epoch [13/15], Step [600/2100], Loss: 0.0074\n",
      "Epoch [13/15], Step [700/2100], Loss: 0.0263\n",
      "Epoch [13/15], Step [800/2100], Loss: 0.0006\n",
      "Epoch [13/15], Step [900/2100], Loss: 0.0002\n",
      "Epoch [13/15], Step [1000/2100], Loss: 0.0069\n",
      "Epoch [13/15], Step [1100/2100], Loss: 0.0130\n",
      "Epoch [13/15], Step [1200/2100], Loss: 0.0105\n",
      "Epoch [13/15], Step [1300/2100], Loss: 0.0158\n",
      "Epoch [13/15], Step [1400/2100], Loss: 0.1576\n",
      "Epoch [13/15], Step [1500/2100], Loss: 0.0022\n",
      "Epoch [13/15], Step [1600/2100], Loss: 0.0725\n",
      "Epoch [13/15], Step [1700/2100], Loss: 0.0002\n",
      "Epoch [13/15], Step [1800/2100], Loss: 0.0005\n",
      "Epoch [13/15], Step [1900/2100], Loss: 0.2048\n",
      "Epoch [13/15], Step [2000/2100], Loss: 0.0039\n",
      "Epoch [13/15], Step [2100/2100], Loss: 0.0014\n",
      "Accuracy of the network on the 10000 test images: 96.51190476190476 %\n",
      "Epoch [14/15], Step [100/2100], Loss: 0.0006\n",
      "Epoch [14/15], Step [200/2100], Loss: 0.0006\n",
      "Epoch [14/15], Step [300/2100], Loss: 0.0001\n",
      "Epoch [14/15], Step [400/2100], Loss: 0.0002\n",
      "Epoch [14/15], Step [500/2100], Loss: 0.0107\n",
      "Epoch [14/15], Step [600/2100], Loss: 0.0002\n",
      "Epoch [14/15], Step [700/2100], Loss: 0.0700\n",
      "Epoch [14/15], Step [800/2100], Loss: 0.0000\n",
      "Epoch [14/15], Step [900/2100], Loss: 0.0877\n",
      "Epoch [14/15], Step [1000/2100], Loss: 0.0000\n",
      "Epoch [14/15], Step [1100/2100], Loss: 0.0004\n",
      "Epoch [14/15], Step [1200/2100], Loss: 0.0005\n",
      "Epoch [14/15], Step [1300/2100], Loss: 0.0000\n",
      "Epoch [14/15], Step [1400/2100], Loss: 0.0006\n",
      "Epoch [14/15], Step [1500/2100], Loss: 0.0028\n",
      "Epoch [14/15], Step [1600/2100], Loss: 0.0336\n",
      "Epoch [14/15], Step [1700/2100], Loss: 0.0002\n",
      "Epoch [14/15], Step [1800/2100], Loss: 0.0115\n",
      "Epoch [14/15], Step [1900/2100], Loss: 0.0017\n",
      "Epoch [14/15], Step [2000/2100], Loss: 0.0011\n",
      "Epoch [14/15], Step [2100/2100], Loss: 0.0002\n",
      "Accuracy of the network on the 10000 test images: 96.35714285714286 %\n",
      "Epoch [15/15], Step [100/2100], Loss: 0.0019\n",
      "Epoch [15/15], Step [200/2100], Loss: 0.0002\n",
      "Epoch [15/15], Step [300/2100], Loss: 0.0001\n",
      "Epoch [15/15], Step [400/2100], Loss: 0.0001\n",
      "Epoch [15/15], Step [500/2100], Loss: 0.1524\n",
      "Epoch [15/15], Step [600/2100], Loss: 0.0004\n",
      "Epoch [15/15], Step [700/2100], Loss: 0.0000\n",
      "Epoch [15/15], Step [800/2100], Loss: 0.0005\n",
      "Epoch [15/15], Step [900/2100], Loss: 0.0000\n",
      "Epoch [15/15], Step [1000/2100], Loss: 0.0000\n",
      "Epoch [15/15], Step [1100/2100], Loss: 0.0000\n",
      "Epoch [15/15], Step [1200/2100], Loss: 0.0001\n",
      "Epoch [15/15], Step [1300/2100], Loss: 0.0000\n",
      "Epoch [15/15], Step [1400/2100], Loss: 0.0092\n",
      "Epoch [15/15], Step [1500/2100], Loss: 0.0011\n",
      "Epoch [15/15], Step [1600/2100], Loss: 0.0005\n",
      "Epoch [15/15], Step [1700/2100], Loss: 0.2398\n",
      "Epoch [15/15], Step [1800/2100], Loss: 0.0001\n",
      "Epoch [15/15], Step [1900/2100], Loss: 0.0002\n",
      "Epoch [15/15], Step [2000/2100], Loss: 0.0041\n",
      "Epoch [15/15], Step [2100/2100], Loss: 0.0002\n",
      "Accuracy of the network on the 10000 test images: 96.51190476190476 %\n"
     ]
    }
   ],
   "source": [
    "total_step = len(train_loader)\n",
    "for epoch in range(15):\n",
    "    model_3.train()\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # Move tensors to the configured device\n",
    "        images = images.reshape(-1,1,28,28).to(device).float()\n",
    "        labels = labels.to(device)\n",
    "        labels = labels.squeeze(1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model_3(images)\n",
    "        loss = F.nll_loss(outputs, labels)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if (i+1) % 100 == 0:\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, 15, i+1, total_step, loss.item()))\n",
    "\n",
    "        \n",
    "\n",
    "            \n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model_3.eval()\n",
    "        for images, labels in test_loader:\n",
    "            images = images.reshape(-1,1,28,28).to(device).float()\n",
    "            labels = labels.to(device)\n",
    "            labels = labels.squeeze(1)\n",
    "            outputs = model_3(images)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print('Accuracy of the network on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
