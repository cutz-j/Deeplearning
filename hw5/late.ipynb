{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "late.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKaHylrQc5S3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "321d0187-31cb-4612-c60a-b3a0d5451c9d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('./gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "4/3wEUHnZuZwqf8c-p214xM8MmA0eQixhVLCD9gFNfrw3_wCpbnooJYWE\n",
            "Mounted at ./gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26jRcNqtYldP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "d21abc8f-837e-449a-bb66-69f4e1dbfe22"
      },
      "source": [
        "!ls\n",
        "%cd skk_CS231_study/\n",
        "\n",
        "# %cd ."
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AIChallenge_project\t   PerspectiveImages_cleaning\n",
            " 이상행동cctv_제안서.png   poseEstimation_YOLOv3\n",
            " CS231.zip\t\t   skk_CS231_study\n",
            " data\t\t\t   Untitled0.ipynb\n",
            " DFD_STUDY\t\t  'Untitled Diagram (1).png'\n",
            " emnist\t\t\t  'Untitled Diagram (2).png'\n",
            " FaceObjectDetect.py\t  'Untitled Diagram.drawio'\n",
            " HAI_anomalyDtec\t  'Untitled Diagram.png'\n",
            " PerspectiveImages\t   xception\n",
            "/content/gdrive/My Drive/skk_CS231_study\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyDDL_2bweWf",
        "colab_type": "text"
      },
      "source": [
        "## ***Train Data set 구축 및 전처리***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I33QN4Trd8-A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c0e5c6be-dc54-495f-ade6-4641467edef5"
      },
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def detect_num(contours):\n",
        "    # print(len(contours))\n",
        "    box=[]\n",
        "    for i in range(len(contours)):\n",
        "        cnt = contours[i]\n",
        "        area = cv2.contourArea(cnt)\n",
        "        x,y,w,h = cv2.boundingRect(cnt)\n",
        "        rect_area = w*h\n",
        "        aspect_ratio = float(w)/h\n",
        "        if rect_area>=600 and rect_area<=900:\n",
        "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),1)\n",
        "            rect_coord = (cv2.boundingRect(cnt))\n",
        "            if box and box[-1][0] == rect_coord[0]:\n",
        "                continue\n",
        "            else:\n",
        "                box.append(rect_coord)\n",
        "    box = sorted(box)\n",
        "    print(box)\n",
        "    return box\n",
        "\n",
        "params = list(net.parameters())\n",
        "print(params[0].size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6, 3, 3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQ3Z4kS-y1wa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x = [28,50,73,109,131,152,172]\n",
        "y = 32\n",
        "cnt =0\n",
        "lamb_check_coord = lambda x, coord : x<coord[0]+coord[2] and x>coord[0] and 32<coord[1]+coord[3] and 32>coord[1] and coord[3]>coord[2]\n",
        "def save_coord_respectively(coordbox,img,num_name,str_name):\n",
        "    print(\"save_coord_respectively\")\n",
        "    global x,y,cnt\n",
        "    name=\"\"\n",
        "    for coord in (coordbox):\n",
        "        for j in range(len(x)):\n",
        "            if lamb_check_coord(x[j],coord):\n",
        "                if (num_name[j]!=-1):\n",
        "                    name = str(num_name[j])\n",
        "                else:\n",
        "                    name = str_name\n",
        "                try:\n",
        "                    name = name+'_'+datetime.datetime.now().strftime(\"%y%m%d_%H%M%S\")\n",
        "                    while (name+'.jpg' in os.listdir('.//train__//')):\n",
        "                        name +='_'\n",
        "                    cv2.imwrite('.//train__//'+ name+'.jpg',img[coord[1]:coord[1]+coord[3],coord[0]:coord[0]+coord[2]])\n",
        "                    print(cnt)\n",
        "                    cnt+=1\n",
        "                except:\n",
        "                    \"error\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gyqFYwxYxo8c",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "701c5681-7c4b-4a08-cd98-9845af04cc00"
      },
      "source": [
        "import cv2\n",
        "import copy\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "path = \"./PerspectiveImages_cleaning\"\n",
        "pps = os.listdir(\"./PerspectiveImages_cleaning\")\n",
        "file_cnt=0\n",
        "print(len(pps))\n",
        "contours_arr = []\n",
        "\n",
        "for n in (pps):\n",
        "    path_=os.path.join(path,n)\n",
        "    s = path_.split(\"/\")[2].split('.')[0]\n",
        "    if len(s)!=8:continue\n",
        "    num_name=[]\n",
        "    str_name=''\n",
        "    for i in range(len(s)):\n",
        "        if(s[i]<='9' and s[i]>='0'):\n",
        "            num_name.append(s[i])\n",
        "        else:\n",
        "            str_name+=s[i]\n",
        "    num_name.insert(2,-1)\n",
        "    img = cv2.imread(path_,0)\n",
        "    img_origin = copy.deepcopy(img)\n",
        "    img = cv2.adaptiveThreshold(img, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C , cv2.THRESH_BINARY, 201, 2)\n",
        "    blur = cv2.GaussianBlur(img,(3,3),0)\n",
        "    canny = cv2.Canny(blur,0,250)\n",
        "    contours, _ = cv2.findContours(canny, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    box = detect_num(contours)\n",
        "\n",
        "    name_cnt =0\n",
        "    save_coord_respectively(box,img_origin, num_name,str_name)\n",
        "    file_cnt+=1\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "628\n",
            "[(64, 18, 19, 35), (101, 14, 17, 43), (125, 15, 15, 42)]\n",
            "save_coord_respectively\n",
            "sfd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sfd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "sfd\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAG8AAAD6CAYAAACvbhmQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAT00lEQVR4nO2de4xc91XHv2fuvPa93qc39jp+JsYkqls5FjSA2pSgEBABCaGmCAGKFPijUlERxIU/KIhKrQQUEIgqhZBUgqRVadWoSinGTVUqosaJm6ROHMeP2PE6a+/au+udfc3rHv6Yu+3MnHO9d153+dXnI1m7c3zv3N/Mmd/cs+d8f+dHzAzDTRKbPQCjecx5DmPOcxhznsOY8xzGnOcwLTmPiB4gotNEdJaIjrRrUEY0qNm/84jIA/AWgPsBTAE4DuBhZn4j7JzkQDdnxgZqbKWy8vlhij6OhBw/kbSprzLkOupbUpLjTBQ3GNz683kh9rQvbD2ZgrDNv3ntGjOP1tuT0S6vchjAWWY+DwBE9AyAhwCEOi8zNoCf+PvfrbHNLfSK48qF6F8IqS75DqbTZWHzfekoDnFesSDfFp7JCFt2Jto4iwP6BPEn14Tt8M4LwvbF93/+onZ+K1+b2wBcqno8FdiMmOh4wEJEjxLRS0T0UmlxpdOXu6VoxXmXAUxWPd4e2Gpg5seZ+RAzH0r2d7dwOaOeVu55xwHsI6JdqDjtwwA+crMTSuWEuMep95IF/TOVkPdylLrTwlZQAoTkinJ/C/noZkrS1jsl71vdM/J+6yfldRZ36G/zyi7l3ozowVrTzmPmEhF9FMA3AXgAnmDm15t9PqNxWpl5YObnADzXprEYDWIZFocx5zlMS1+bDeMTyqu10UQqL2/QWmACAKllaUuU5fnllDyOZDJDtQFQ0zHpJXlw19lr8tSerLAtjw+ql0mnZWQ0kFoNGZTEZp7DmPMcxpznMOY8hzHnOUys0SYlfXQN1pZB8hmZIiqOhRTAGigVCZS6XyglGcH2TskxUVFGi7SwJGyc1KPNgS5ZErotcyPKCAHYzHMac57DmPMcxpznMLEGLBmvjJ3Dc219zqIvA4mSLz+Tw1kltxbCubkRaaQt0laSwRYPSE1Ofoteo5vIylRYt5ffeIABNvMcxpznMOY8h2npnkdEFwDkAJQBlJj5UDsGZUSjHQHLB5lZFrYUsl4Rd/TPNH0hD7KmVlTkyCXFNp5eFLa8r7/8169MCFv/nAxOkJaFw6V9MpuyMqmcC2BHz7ywDXhWz7slaNV5DOC/iOhlInq0HQMyotPq1+bPMPNlIhoDcJSI3mTm71QfEDj1UQDo22qi23bS0sxj5svBzxkAX0Vl8Un9MT9UTHdtkQJbo3mannlE1AMgwcy54PdfAPAXNzsnmyjiQPe7NTYtCOkLuWmv+TJA8JTlXFmSSmZPURu9sLRXvU5hqkfYuq7IUo8/II+7fkC+pRN7rqjXOdj7jrCNJWVgFUYrX5vjAL5KROvP8+/M/J8tPJ/RIK3I3c8DeE8bx2I0iP2p4DDmPIeJtSTkkY9Br7Y0kyaZfRjyZHAAADlfqpH7ElIHcndKLuK8WJJZl3++8bPqdQZOyxKOd3VB2PJ7xoRt5Xapa/nQyCVhA4Bh5XVqwVYYNvMcxpznMOY8hzHnOYw5z2FijTaTKKsRVj39pItwRpPRWoH0J2RUerksk+KnLm1Vz99xQekokJJv1cJemavtHZeK5zu79fSYlrJbY2VxYQg28xzGnOcw5jyHMec5TKwBS4IYPVTbLWDBj15dLyqftds8XdxTz8nVSWHrfrVLPbbr/FVhKw9JJfTCfllLPDw2LWxhKa++hKxb5nx9TBo28xzGnOcw5jyH2dB5RPQEEc0Q0ckq2xARHSWiM8FPZQmN0WmiBCxPAvgHAF+osh0BcIyZPx00Bj8C4LGNnohBKCBkvXkVi6yrzAZJ1u66SWYkpssyE/Ps5buFbeIFPWNDqzLDs/he0eIZ2d05YdvZfV0eF7UZdYNsOPMCHWb9orqHADwV/P4UgF9t87iMCDR7zxtn5vWY+AoqSjIjZloOWLjS2z+0T0Z1j+kb16P9TWZEo1nnXSWiCQAIfoYu/alWTA8Mb3y/M6LTbIblWQC/DeDTwc+vRTqLAZ9rPy8pUsovIfQox6ZIZiS+uSyV0LMn5Dd730sn1OuU75LnL+yTn/PJAVn+2ZaRy7bCXmOR5dvfVgESET0N4AUAdxLRFBE9gorT7ieiMwB+PnhsxMyGM4+ZHw75rw+1eSxGg1iGxWHMeQ4Ta0mIAZTrNn2oLxEBwEBC17DsScmyzFRJamI+d+7nhG3ymLwO5/XrLN7RJ2yru+X5fWmZ8UkpCnAtMAnDFNO3COY8hzHnOYw5z2FiDVh8JIRGY1TZ6WLY01OlK74MGrRsyuKrw8I2euJN+YQH7lCvc2O3/Ex39cvgxFd2vrxRlhmfrBKUAXrmJRG6U4fEZp7DmPMcxpznMOY8hzHnOUy8W7ApaDW6RMi+qdNlGbV949pdwtZ3QZ5LvbJb0bVDMioFgNVtckyajnlmRabRrvQMCFs2pJ43nNx4udvNsJnnMOY8hzHnOUyziulPEtFlInol+PdgZ4dpaDSrmAaAzzLzXzVysQR8saxpICGDk7AEUU5p2Xj6muxC1C0zWci97zZp26EHRok+WVMrleTnfKUgx3NyQV5ntT+tX0dJhe1Mz6rHqudvdECIYtr4f0Ar97yPEtFrwdeqLTTZBJp13j8B2APgIIBpAH8ddmCNYlprb280TVPOY+arzFxmZh/A56H0lq469keK6SFTTLeTpjIsRDRRtdDk1wCcvNnx63jEosWitkRrTqnbAcD/rMj629K8XNOekT10MLtLvtT8sB4aJZPSXsrL81eVuuM7eT040ehLyshqtJ09pgPF9AcAjBDRFIA/A/ABIjqIiiDsAoDfi3xFo200q5j+lw6MxWgQy7A4jDnPYWItCaXgY2vdtpp5lp+fs8V+9fznryuCISXmWLhTBhLabp6c0QMWX9m2VKtS+b40FpXA5kpOlo4A4FqPVIDnstZE55bAnOcw5jyHMec5TKwBSxmE5bpgoKiURWbK+g1ew+uS+dKyUr7xMzK4oC5dW5LQOgmSfE7PU7ZBVZ5vLa+3Hp7Ny4Bluii3LQ3DZp7DmPMcxpznMOY8hzHnOcymK6aXlcX2OWWNGwBsScuezOPDsgvRYrcs6BUK8jrptB5tlsvaZ1pGlqmkjEoV7RMKKyHR5opUcV/qiq4osZnnMOY8hzHnOUwUxfQkET1PRG8Q0etE9LHAbn2mN5koAUsJwB8y8wki6gPwMhEdBfA7aLDPNEHZlJ6jb3K/v1duONGXkiHCzJpMry2VZN/qfEl/+XOrUtRE9eMGkFLSaEs5Rf0UErDkVuWxs2syZRZGFMX0NDOfCH7PATgFYBusz/Sm09A9j4h2AngvgO8hYp/patHt/Fz0NhXGxkR2HhH1AvgPAH/AzDXiwpv1ma4W3W4ZsvionUR6N4kohYrj/o2ZvxKYI/eZNjpDFNEtoaLTPMXMf1P1X831ma5DBDDQN38HAC8tjx1PygzLXFbe9G+UZBAyr9gA4KwnN8DQ0DogTbOsx3k5fY4UlIbpBT960ivKkfcC+C0APyCiVwLbn6DitC8FPacvAviNyFc12kIUxfR3oQrfAFif6U3FIgiHMec5TPw9putu8lrAUr8MbB1tD3Ftr/GehFwiNpqUO24t+/puYVogMleQ5ZuVkhyPmonJ6XedNaVMpV07DJt5DmPOcxhznsOY8xwm9oAlz7VZhW6lI15fyMYQOcWubTgx6Mm+1VGPA4CVrmjrykssS0+esp49qVe4wAU5d4p+9KYLNvMcxpznMOY8hzHnOYw5z2FijjYJhbrPS0ZJB2kpM0BPm2lRpLYNmqcU+sO2O1tQUmkznmxyMEcyZaZFm57e0AlQ1hGWtGYGIdjMcxhznsOY8xymFcW09ZneZFpRTAMN9pkuMyHn16qE0wl5g0/oKkL4SreksA3k61lmmfIK2+5MC2QyCXmdnqRsq6R1RVJaYwMAqCCP5QbqeVE0LNOodLMFM+eIaF0xbWwyrSimgQh9pq1NcedoRTEdqc+0tSnuHE0rphvpM210hqYV0830mWaQyIisKRmSRMi2GAVEm7laYLPmy4BFy7o0wmAqpFAnBhRiV2KTjBctAANaU0w/bH2mN5dWFNPPtX84RiNYhsVhzHkOE2tJqAQP18u1y68Wfbkuuz9EMd2dkBmNqEGHpqwOQxMmZRN6+ageVjIsoacqQ88kowcsNvMcxpznMOY8hzHnOUysAcuqn8ZrK5MbHjeRXlDtB7PvRLpOWfmzVCvzhGlYBhMyc9KtLBtbUbI2xTX5lnqF6JmcpKK/CcNmnsOY8xzGnOcw5jyHMec5TKzR5nIpjRev3V47AEWAtK9faXsIYGf6mrD1KZFhVLSoFAAySsQ3npIR8A2tF/aqUnNsoGxYYlufd0tgznMYc57DRFFMZ4noRSJ6NVBM/3lg30VE3yOis0T0RSKKvkG40RaiBCx5APcx81KgIvsuEX0DwMdRUUw/Q0SfA/AIKnLAUApFD5dma+WdqZQMDoaz+kL/gnIz15ZzpaFtViGjBq2jUhg7UzJYejs/JsezIMcYVkrkpBxTW5d4cYX1Bpip4B8DuA/AlwO79ZjeBKLqNr1AOTYD4CiAcwAWmHm97DuFEAl8tWK6nNNnlNEckZwXiGsPAtiOirh2f9QLVCumvT65ktRonoaiTWZeAPA8gJ8GMEhE6/fM7QAut3lsxgZEUUyPAigy8wIRdQG4H8BnUHHirwN4BlF7TJcS8K/Xtklc61E2lijqrRTXlLVSmjoaShDTSD1PI6s85w9y8k7RNavsTcshKZa00i1JyTiFESXanADwFBF5qMzULzHz14noDQDPENFfAvg+KpJ4I0aiKKZfQ2VZV739PGxxyaZiGRaHMec5TKwlIfKBZN0GEUofGRTLelkk58sSzIIvN7bQykRaA56w1pBaE5+rygYar169TdiyC9HrP16XDIJ6lXXuYdjMcxhznsOY8xzGnOcw8Xb9I0AsQS/JjMT8mr5P+nxJ5kaLSpno/d1nhC2tLAyfVYIdANidlLuIvVXYKmxrZwaEbeRdGQTN7ddLnemMPHYsKzsOhmEzz2HMeQ5jznMYc57DxBqwgIBy1he2elby+g3+7ZURYdvVLbUlZ5Tg4h5ledhISIblfEluW/r01D3CNnhKnpu9ItUC/t3669nSuyJsE2m5jWoYNvMcxpznMOY8h2lFdPskEb1d1ab4YOeHa1TTiugWAP6Imb98k3ONDhJFBsEANNFt43gM7qvr8FOW4WahoNfz5gsybTaSkcvBzq6NC9tPZS8KW5b0JV5fm3+fsL37oqzd7XptUdj8jHxL10b0t+sn++SyMa1xQRhNiW6Zeb1N8aeCNsWfJSJd8mV0jKZEt0R0F4BPoCK+vQfAEIDHtHNNMd05mhXdPsDM08E6hjyAf0WIkswU050jSrQ5SkSDwe/rots3iWgisBEqi0w2bFNstJdWRLffCtTUBOAVAL+/4TMRw8vUim78ovz8+CHLnGZW5B6tGqNZWY97OS/VzdoSLQD4yvFDwjZ5XIqFEktSLLS0f0jYeIe+bn63ktoL26hDoxXR7X2Rr2J0BMuwOIw5z2HMeQ4Tr2KagET9Eqak0pM5ZNvRuSUpGMqX5EtIezK4ePLyvcJ26pzMmgDA2P/KDE/2qqy9reyV2yctb5Xnbh/RW1Du73pX2MK2XNWwmecw5jyHMec5jDnPYWIOWBjpdG0wUVQ0QNrGEgBQKMjhlooyQDhdlpmTGxelunnwLb301HVdDqowKEVE83vlGvncHhksHRq8ql6nRyn/hHUi1LCZ5zDmPIcx5zmMOc9hYg1YEsToStcGA9q+4mtrusKY8zLAKCtLxBanpdald0rZY31Jz2asDsm3pdAvr5PbLcs3d71HamX2ds+o11F3FtOaAoVgM89hzHkOY85zmEY2ufeI6PtE9PXgsbUp3mQamXkfA1C9qOkzqLQp3gtgHpU2xUaMRIo2iWg7gF8C8CkAHw8UY/cB+EhwyFMAPokNekx7CR+DXbVinLISba4u6ptiJJaU/s2K4jq9oLRNVHY2K/bqqaiiXJ6HtWEZmY7fMStsh7dcELYBTxcgqW0kI+5NC0SfeX8L4I+BH7ZUGEbENsVG54ii2/xlADPM/HIzF6hWTBduNL91jCGJ8rV5L4BfIaIHAWQB9AP4OwRtioPZF9qmmJkfB/A4APTfOd7cAhVDJUpr/k8w83Zm3gngwwC+xcy/iR+1KQaitik22kor6bHH0GCb4mTCF2rm68tSVJRQNsoAAPbkcMmXk5mUIKggy3koZ/UvgtKATFsNbJcL/T+4VXZamlB2++oLCVg0GqnnNeQ8Zv42gG8Hv1ub4k3GMiwOY85zGHOewxCHbdjQiYsRzQJYL3iNAJBrnNyk06/ldmYerTfG6ryaCxO9xMxyIZyDbNZrsa9NhzHnOcxmOu/xTbx2u9mU17Jp9zyjdexr02Fidx4RPUBEpwP5xJG4r98qRPQEEc0Q0ckq2xARHSWiM8FPueqyA8TqvKAdyD8C+EUABwA8TEQH4hxDG3gSwAN1tiMAjjHzPgDHgscdJ+6ZdxjAWWY+z8wFVHa9fCjmMbQEM38HwFyd+SFUpCBAjDtXx+28bQAuVT3+cZFPjDPzdPD7FQCy7WAHsIClzQQtLmMJ4eN23mUAk1WPf1x2eb5a1YttApXWlh0nbucdB7AvEOymUZFVPBvzGDrBs6hIQYA4JSHMHOs/AA8CeAvAOQB/Gvf12zD+pwFMAyiics9+BBUp5DEAZwD8N4ChOMZiGRaHsYDFYcx5DmPOcxhznsOY8xzGnOcw5jyHMec5zP8BOoF/qMqnKIwAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SwrGTLH1fhH3",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EpiuVv59wxhq",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UOjmc5gqwyUN",
        "colab_type": "text"
      },
      "source": [
        "## ***val 데이터 셋 구축***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sEyLgN5pmnx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "CROP_DATA = [(15, 5, 25, 55), (38, 5, 25, 55), (60, 10, 25, 45),(60, 10, 25, 45), (95, 10, 25, 50), (115, 10, 28, 50), (140, 5, 25, 52), (160, 7, 22, 50)]\n",
        "\n",
        "path = './val__/'\n",
        "file_list = os.listdir(path)\n",
        "# print(file_list)\n",
        "for i in range(len(file_list)):\n",
        "    # if i!=1 :continue\n",
        "    file_name = path+file_list[i]\n",
        "    if '.jpg' not in file_name:\n",
        "        continue\n",
        "    img = cv2.imread(file_name)\n",
        "    for IND in range(8):\n",
        "        char_file = file_list[i][IND]\n",
        "        if(char_file >='6') :continue\n",
        "        print (file_list[i])\n",
        "        _ = '_'\n",
        "        if IND==2 or IND==3 :\n",
        "            # print(IND)\n",
        "            continue\n",
        "        while (char_file+_+file_list[i] in os.listdir('./val__/'+char_file)):\n",
        "            _ +='_'\n",
        "        cv2.imwrite('./val__//'+char_file+'//'+char_file+_+file_list[i],img[CROP_DATA[IND][1]:CROP_DATA[IND][1]+CROP_DATA[IND][3],\n",
        "                CROP_DATA[IND][0]:CROP_DATA[IND][0]+CROP_DATA[IND][2]\n",
        "                ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OLvy7vBEz9G6",
        "colab_type": "text"
      },
      "source": [
        "## ***Data Loader(train,validation) & Building Datasets***\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QbWZzMx4dKbW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision import transforms\n",
        "import torchvision\n",
        "import numpy as np\n",
        "from scipy.ndimage.filters import gaussian_filter\n",
        "from PIL import Image\n",
        "\n",
        "def gaussian_blur(img, sigma):\n",
        "    gaussian_filter(img[:,:,0], output=img[:,:,0], sigma=sigma)\n",
        "    gaussian_filter(img[:,:,1], output=img[:,:,1], sigma=sigma)\n",
        "    gaussian_filter(img[:,:,2], output=img[:,:,2], sigma=sigma)\n",
        "\n",
        "def data_augment(img):\n",
        "    img = np.array(img)\n",
        "    if np.random.random() < .5:\n",
        "        sig = np.random.uniform(0.0, 3.0)\n",
        "        gaussian_blur(img, sig)\n",
        "\n",
        "    return Image.fromarray(img)\n",
        "\n",
        "train_aug = transforms.Compose([\n",
        "    transforms.Lambda(lambda img: data_augment(img)),##undefitting시 주석할 것\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.RandomErasing(p=0.1, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
        "])\n",
        "val_aug = transforms.Compose([\n",
        "    # transforms.Lambda(lambda img: data_augment(img)),##undefitting시 주석할 것\n",
        "    transforms.Resize((32,32)),\n",
        "    transforms.ToTensor(),\n",
        "    # transforms.RandomErasing(p=0.1, scale=(0.02, 0.10), ratio=(0.3, 3.3), value=0, inplace=True),\n",
        "])\n",
        "trainset = torchvision.datasets.ImageFolder(root = './train__',\n",
        "                                           transform = train_aug)\n",
        "valset = torchvision.datasets.ImageFolder(root = './val__',transform= train_aug)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l1w2KjldziNk",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vx9jwY_4xIgi",
        "colab_type": "text"
      },
      "source": [
        "Train / Validation Loader 구축 및 DataSet생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYCkr1LElai6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader\n",
        "trainloader = DataLoader(trainset,batch_size=29,shuffle=True,num_workers=4)\n",
        "valloader = DataLoader(valset,batch_size=29,shuffle=False,num_workers=4)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VkhqCrnkz2ON",
        "colab_type": "text"
      },
      "source": [
        "Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9nR-xoORFeHw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        },
        "outputId": "db5e55a9-17bf-4646-ae3e-34f630f0ad65"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "# class Net(nn.Module):\n",
        "\n",
        "#     def __init__(self):\n",
        "#         super(Net, self).__init__()\n",
        "#         # 1 input image channel, 6 output channels, 3x3 square convolution\n",
        "#         # kernel\n",
        "#         self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "#         self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "#         # an affine operation: y = Wx + b\n",
        "#         self.fc1 = nn.Linear(16 * 6 * 6, 128)  # 6*6 from image dimension\n",
        "#         self.fc2 = nn.Linear(128, 256)\n",
        "#         # self.bn1 = nn.BatchNorm2d(84)\n",
        "#         self.fc3 = nn.Linear(256, 128)\n",
        "#         self.fc4 = nn.Linear(128, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         # Max pooling over a (2, 2) window\n",
        "#         x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
        "#         # If the size is a square you can only specify a single number\n",
        "#         x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "#         x = x.view(-1, self.num_flat_features(x))\n",
        "#         x = F.relu(self.fc1(x))\n",
        "#         x = F.relu(self.fc2(x))\n",
        "#         x = F.relu(self.fc3(x))\n",
        "#         x = F.relu(self.fc4(x))\n",
        "\n",
        "#         # y = F.softmax(self.fc4(x), dim=1)\n",
        "#         return x\n",
        "\n",
        "#     def num_flat_features(self, x):\n",
        "#         size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "#         num_features = 1\n",
        "#         for s in size:\n",
        "#             num_features *= s\n",
        "#         return num_features\n",
        "\n",
        "\n",
        "class CNNClassifier(nn.Module):\n",
        "    \n",
        "    def __init__(self):\n",
        "        # 항상 torch.nn.Module을 상속받고 시작\n",
        "        super(CNNClassifier, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3,10,5)\n",
        "        self.pool1 = nn.MaxPool2d(2,2)\n",
        "        self.conv2 = nn.Conv2d(10,20,5)\n",
        "        self.pool2 = nn.MaxPool2d(2,2)\n",
        "        self.fc1 = nn.Linear(960,50)\n",
        "        self.fc2 = nn.Linear(50,10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.pool1(F.relu(self.conv1(input)))\n",
        "        x = self.pool2(F.relu(self.conv2(x)))\n",
        "        x = x.view(x.size(0),-1)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        return x\n",
        "    def num_flat_features(self, x):\n",
        "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
        "        num_features = 1\n",
        "        for s in size:\n",
        "            num_features *= s\n",
        "        return num_features\n",
        "net = CNNClassifier().cuda()\n",
        "print(net)\n"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CNNClassifier(\n",
            "  (conv1): Conv2d(3, 10, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(10, 20, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=960, out_features=50, bias=True)\n",
            "  (fc2): Linear(in_features=50, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "leoRRBO6mkVD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.optim as optim\n",
        "import cv2\n",
        "optimizer = optim.Adam(net.parameters(), lr=0.004)\n",
        "criterion = nn.CrossEntropyLoss().cuda()"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7dvNGP7zv42",
        "colab_type": "text"
      },
      "source": [
        "train Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NaYBrgA8J8AT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        },
        "outputId": "aba67513-b59f-4d38-b7e6-3da859bc685e"
      },
      "source": [
        "nb_epochs = 2000\n",
        "net.train()\n",
        "for epoch in range(nb_epochs+1):\n",
        "    total,correct=0,0\n",
        "    \n",
        "    for idx, (x_train, y_train) in enumerate(trainloader):\n",
        "        x_train,y_train = x_train.cuda(),y_train.cuda()\n",
        "        prediction = net(x_train)\n",
        "        loss = criterion(prediction, y_train)\n",
        "        _, predicted = torch.max(prediction.data, 1)\n",
        "        total += y_train.size(0)\n",
        "        correct += (predicted == y_train).sum().item()\n",
        "        # init gradient 0\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        # W b Update\n",
        "        optimizer.step()\n",
        "        if idx%50==0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, idx * len(x_train), len(trainloader.dataset),100. * idx / len(trainloader), loss.item()))\n",
        "            print(\"accuracy = {}\".format(correct*100/total))\n"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-84-09b3c891c06c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-79-ca66d5bc914a>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 419\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    414\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[1;32m    415\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0;32m--> 416\u001b[0;31m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: conv2d(): argument 'input' (position 1) must be Tensor, not method"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8iSBRTTFzrGg",
        "colab_type": "text"
      },
      "source": [
        "Model test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7c2ZOHt3K7Ax",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "20eb2b14-2e67-41a9-b0b4-23853984da70"
      },
      "source": [
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "net.eval()\n",
        "with torch.no_grad():\n",
        "    for data in valloader:\n",
        "        images, labels = data\n",
        "        images = images.cuda()\n",
        "        labels = labels.cuda()\n",
        "        # print(labels)\n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1) # prediction\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(len(labels)):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (str(i), 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of     0 : 53 %\n",
            "Accuracy of     1 :  0 %\n",
            "Accuracy of     2 : 60 %\n",
            "Accuracy of     3 : 46 %\n",
            "Accuracy of     4 : 66 %\n",
            "Accuracy of     5 : 27 %\n",
            "Accuracy of     6 : 53 %\n",
            "Accuracy of     7 :  0 %\n",
            "Accuracy of     8 :  0 %\n",
            "Accuracy of     9 :  0 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}