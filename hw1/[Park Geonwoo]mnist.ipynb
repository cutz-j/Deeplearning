{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-MNIST(2)",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u8aZgMeu3qY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "c4e355c0-d85d-4abd-ceb0-6c8058fde011"
      },
      "source": [
        "from __future__ import print_function\n",
        "import torch\n",
        "import torchvision\n",
        "\n",
        "m_train = torchvision.datasets.MNIST(root=\"MNIST_data/\",train=True,transform=torchvision.transforms.ToTensor(),download=True)\n",
        "m_test = torchvision.datasets.MNIST(root=\"MNIST_data/\",train=False,transform=torchvision.transforms.ToTensor(),download=True)\n",
        "\n",
        "data_loader = torch.utils.data.DataLoader(m_train,batch_size=1000, shuffle=True, drop_last=True)\n",
        "test_loader = torch.utils.data.DataLoader(m_test)\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "class MnistModel(torch.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MnistModel, self).__init__()\n",
        "\n",
        "    self.conv1 = torch.nn.Conv2d(1, 32, 5, padding=2)\n",
        "    self.conv2 = torch.nn.Conv2d(32,64,5,padding=2)\n",
        "\n",
        "    self.fc1 = torch.nn.Linear(64*7*7,1024)\n",
        "    self.fc2 = torch.nn.Linear(1024,10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv1(x)),2)\n",
        "    x = torch.nn.functional.max_pool2d(torch.nn.functional.relu(self.conv2(x)),2)\n",
        "    x = x.view(-1,64*7*7)\n",
        "    x = torch.nn.functional.relu(self.fc1(x))\n",
        "    x = torch.nn.functional.dropout(x, training=self.training)\n",
        "    x = self.fc2(x)\n",
        "    return torch.nn.functional.log_softmax(x)\n",
        "\n",
        "\n",
        "model = MnistModel().to(device)\n",
        "\n",
        "total_batch = len (data_loader)\n",
        "epoch = 10\n",
        "model_train=model.train()\n",
        "for epo in range(epoch):\n",
        "  total_cost = 0\n",
        "  for x, y in data_loader:\n",
        "    x = x.to(device)\n",
        "    y = y.to(device)\n",
        "    opt = torch.optim.Adadelta(model_train.parameters(), lr=1.0)\n",
        "    opt.zero_grad()\n",
        "    output = model_train(x)\n",
        "    loss = torch.nn.functional.nll_loss(output, y)\n",
        "    loss.backward()\n",
        "    opt.step()\n",
        "\n",
        "    total_cost += loss\n",
        "\n",
        "  avg_cost = total_cost / total_batch\n",
        "  print(\"에폭: %d\" % (epo+1), \"코스트 = %.9f\" % (avg_cost))\n",
        "\n",
        "test_loss = 0\n",
        "correct = 0\n",
        "\n",
        "model_test=model.eval()\n",
        "with torch.no_grad():\n",
        "  for x_test,y_test in test_loader:\n",
        "    x_test = x_test.to(device)\n",
        "    y_test = y_test.to(device)\n",
        "    output = model_test(x_test)\n",
        "    test_loss += torch.nn.functional.nll_loss(output, y_test, reduction='sum').item()\n",
        "    pred = output.argmax(dim=1, keepdim=True)\n",
        "    correct += pred.eq(y_test.view_as(pred)).sum().item()\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(\"정확도 : \", 100.0 * correct / len(test_loader.dataset),'%')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "에폭: 1 코스트 = 0.882410824\n",
            "에폭: 2 코스트 = 0.131628677\n",
            "에폭: 3 코스트 = 0.076485597\n",
            "에폭: 4 코스트 = 0.056306198\n",
            "에폭: 5 코스트 = 0.047017135\n",
            "에폭: 6 코스트 = 0.037850585\n",
            "에폭: 7 코스트 = 0.033070933\n",
            "에폭: 8 코스트 = 0.028149327\n",
            "에폭: 9 코스트 = 0.025919082\n",
            "에폭: 10 코스트 = 0.021788221\n",
            "정확도 :  99.29 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}