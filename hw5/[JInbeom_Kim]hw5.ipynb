{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "번호판 인식.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "9i6S8OV-Xt0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import glob\n",
        "from google.colab.patches import cv2_imshow\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from unicodedata import normalize\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5lYh6UjaX3HW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "paths = glob.glob('/content/drive/My Drive/PerspectiveImages/' + '*')\n",
        "classes = {'0' : 0, '1' : 1, '2' : 2, '3' : 3, '4' : 4, '5' : 5, '6' : 6, '7' : 7, '8' : 8, '9' : 9, \n",
        "           '가' : 10, '나' : 11, '다' : 12, '라' : 13, '마' : 14, '거' : 15, '너' : 16, '더' : 17, '러' : 18, '머' : 19, \n",
        "           '버' : 20, '서' : 21, '어' : 22, '저' : 23, '고' : 24, '노' : 25, '도' : 26, '로' : 27, '모' : 28, '보' : 29, \n",
        "           '소' : 30, '오' : 31, '조' : 32, '구' : 33, '누' : 34, '두' : 35, '루' : 36, '무' : 37, '부' : 38, '수' : 39, \n",
        "           '우' : 40, '주' : 41, '하' : 42, '호' : 43}\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE4Lgzh8iAKS",
        "colab_type": "text"
      },
      "source": [
        "data_exclusion는 영엽용 번호판과 초록색 번호판을 제외하고 흰색과 검정색으로 구성된 이미지와 그 이미지의 이름을 반환한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgVCaPu7YWgJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_exclusion(paths):\n",
        "    re_data = []\n",
        "    for path in paths:\n",
        "        name = path[-12 : -4]\n",
        "\n",
        "        if name[0].isdigit():   # 영업용(한글로 시작) 제거\n",
        "            # 초록색 제거\n",
        "            cur_img = cv2.imread(path, 0)\n",
        "            blur = cv2.GaussianBlur(cur_img,(5,5),0)\n",
        "            _, img = cv2.threshold(blur,0,255,cv2.THRESH_BINARY+cv2.THRESH_OTSU)\n",
        "\n",
        "            cnt = [0, 0]\n",
        "            for i in range(5, 15):  # 배경 영역인 좌측 상단의 색 판단\n",
        "                if img[i,i] == 0:\n",
        "                    cnt[0] +=1\n",
        "                elif img[i, i] == 255:\n",
        "                    cnt[1] +=1\n",
        "            if cnt[0] < cnt[1]: # 해당 영역에 흰색이 더 많은 경우 초록색이 아니다.\n",
        "                re_data.append((img, name))\n",
        "               \n",
        "    return re_data"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1XOwRHL2hnDF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = data_exclusion(paths)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtjqHmJXhobb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToPILImage(),\n",
        "                                transforms.Resize((32, 224)),\n",
        "                                transforms.ToTensor()])"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeF14NgAhp_y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.zeros((len(data), 32, 224))\n",
        "y = np.zeros((len(data), 7))\n",
        "\n",
        "for i, (img, name) in enumerate(data):\n",
        "    X[i] = transform(img)\n",
        "    y[i, 0] = classes[name[0]]\n",
        "    y[i, 1] = classes[name[1]]\n",
        "    y[i, 3] = classes[name[4]]\n",
        "    y[i, 4] = classes[name[5]]\n",
        "    y[i, 5] = classes[name[6]]\n",
        "    y[i, 6] = classes[name[7]]\n",
        "\n",
        "    hangul = normalize('NFC', name[2: 4])\n",
        "    y[i, 2] = classes[hangul]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UZIH3fvAixBa",
        "colab_type": "text"
      },
      "source": [
        "train, validation, test set을 만들기 위해 이미지와 라벨을 나눈다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhCEahRWh4rS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "a49bd18a-916a-446a-dce4-d3599e588f0d"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1)\n",
        "print(X_train.shape, y_train.shape)\n",
        "print(X_val.shape, y_val.shape)\n",
        "print(X_test.shape, y_test.shape)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(516, 32, 224) (516, 7)\n",
            "(173, 32, 224) (173, 7)\n",
            "(173, 32, 224) (173, 7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV2wOZoHi8P-",
        "colab_type": "text"
      },
      "source": [
        "이미지와 라벨을 받아 데이터셋을 만들어준다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tt__ZPOci378",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, X, y):\n",
        "        self.X = X.reshape(X.shape[0], 1, X.shape[1], X.shape[2])\n",
        "        self.y = torch.LongTensor(y)\n",
        "        print(self.X.shape)\n",
        "        print(self.y.shape)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.y.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx], self.y[idx]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iUW4MO6gjDFK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 121
        },
        "outputId": "16a98b77-23b1-4557-c715-a5ce25e042cc"
      },
      "source": [
        "train_set = CustomDataset(X_train, y_train)\n",
        "val_set = CustomDataset(X_val, y_val)\n",
        "test_set = CustomDataset(X_test, y_test)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(516, 1, 32, 224)\n",
            "torch.Size([516, 7])\n",
            "(173, 1, 32, 224)\n",
            "torch.Size([173, 7])\n",
            "(173, 1, 32, 224)\n",
            "torch.Size([173, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pmt2fcqujJWM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "BATCHSIZE = 16\n",
        "\n",
        "train_loader = DataLoader(train_set, batch_size=BATCHSIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_set, batch_size=BATCHSIZE, shuffle=False)\n",
        "test_loader = DataLoader(test_set, batch_size=BATCHSIZE, shuffle=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5D5dW9bajT0e",
        "colab_type": "text"
      },
      "source": [
        "# CNN + RNN 모델 생성\n",
        "이미지를 CNN에 통과시키고 GRU에 넣는다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6suZonPwjMg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self, hidden_size, output_size, batch_size, num_layers):\n",
        "        super(Net, self).__init__()\n",
        "        self.hidden_size = hidden_size\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(16),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool2d((2, 2)),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "\n",
        "        self.rnn = nn.GRU(2048, hidden_size, num_layers=num_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x, hidden):\n",
        "        n = x.shape[0]\n",
        "        x = self.conv(x)\n",
        "        x = x.reshape(n, 7, 2048)\n",
        "\n",
        "        x, hidden = self.rnn(x, hidden)\n",
        "        x = self.fc(x)\n",
        "        return x, hidden"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71kVXNinkZm1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "fe91c88a-7333-44af-e711-42e6d10ebbb2"
      },
      "source": [
        "def train(train_loader, val_loader, model, batch_size, n_epochs, lr):\n",
        "    optimizer = optim.AdamW(params=model.parameters(), lr=lr, weight_decay=0.0001)\n",
        "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer=optimizer, patience=3, verbose=True)\n",
        "    loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "    best = {\"loss\": sys.float_info.max}\n",
        "    patience = 0\n",
        "\n",
        "    for e in range(n_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for x, y in train_loader:\n",
        "            x = x.type(torch.FloatTensor).to(device)\n",
        "            y = y.to(device)\n",
        "            hidden = torch.zeros(NUMLAYERS, x.shape[0], HIDDENSIZE)\n",
        "            hidden = hidden.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            output, hidden = model(x, hidden)\n",
        "            loss = 0\n",
        "            for i in range(7):\n",
        "                predict = output[:, i]\n",
        "                target = y[:, i]\n",
        "                loss += loss_fn(predict, target)\n",
        "            loss /= 7\n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        valid_loss = 0\n",
        "        with torch.no_grad():\n",
        "            for x, y in val_loader:\n",
        "                x = x.type(torch.FloatTensor).to(device)\n",
        "                y = y.to(device)\n",
        "                hidden = torch.zeros(NUMLAYERS, x.shape[0], HIDDENSIZE).to(device)\n",
        "                output, hidden = model(x, hidden)\n",
        "                loss = 0\n",
        "                for i in range(7):\n",
        "                    predict = output[:, i]\n",
        "                    target = y[:, i]\n",
        "                    loss += loss_fn(predict, target)\n",
        "                valid_loss += loss.item()\n",
        "            valid_loss /= len(val_loader) * 7\n",
        "\n",
        "        if valid_loss < best[\"loss\"]:\n",
        "            best[\"loss\"] = valid_loss\n",
        "            best[\"epoch\"] = e + 1\n",
        "            best[\"state\"] = model.state_dict()\n",
        "            patience = 0\n",
        "\n",
        "        if patience > 5:\n",
        "            print(\"Best loss: %.4f\"%(best[\"loss\"]))\n",
        "            break\n",
        "\n",
        "        if e % 10 == 9:\n",
        "            print(\"[%2d] Train loss : %.4f    Valid loss: %.4f      Best loss: %.4f\"%(e+1, train_loss, valid_loss, best[\"loss\"]))\n",
        "        scheduler.step(metrics=valid_loss)      \n",
        "        patience +=1\n",
        "\n",
        "    return best\n",
        "\n",
        "NUMLAYERS = 3\n",
        "HIDDENSIZE = 50\n",
        "NUM_CLASS = len(classes)\n",
        "model = Net(HIDDENSIZE, NUM_CLASS, BATCHSIZE, NUMLAYERS)\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model.to(device)\n",
        "\n",
        "EPOCH = 150\n",
        "BEST = train(train_loader, val_loader, model, BATCHSIZE, EPOCH, 0.001)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10] Train loss : 1.4012    Valid loss: 1.3964      Best loss: 1.3964\n",
            "[20] Train loss : 0.5103    Valid loss: 0.5914      Best loss: 0.5914\n",
            "Epoch    29: reducing learning rate of group 0 to 1.0000e-04.\n",
            "[30] Train loss : 0.3805    Valid loss: 0.5334      Best loss: 0.5334\n",
            "[40] Train loss : 0.3367    Valid loss: 0.5048      Best loss: 0.5048\n",
            "[50] Train loss : 0.3203    Valid loss: 0.4996      Best loss: 0.4983\n",
            "Epoch    57: reducing learning rate of group 0 to 1.0000e-05.\n",
            "[60] Train loss : 0.3072    Valid loss: 0.4952      Best loss: 0.4915\n",
            "Epoch    62: reducing learning rate of group 0 to 1.0000e-06.\n",
            "Best loss: 0.4915\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KDIkGyEzVVC",
        "colab_type": "text"
      },
      "source": [
        "최적의 모델 저장"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7qh5yKb0s3FX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open(\"model.pt\", \"wb\") as f:\n",
        "    torch.save(\n",
        "        {\n",
        "            \"state\": BEST[\"state\"],\n",
        "            \"best_epoch\": BEST[\"epoch\"],\n",
        "        },\n",
        "        f,\n",
        "    )"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_PHRsYUDzYDT",
        "colab_type": "text"
      },
      "source": [
        "모델을 불러와서 테스트"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhG58eDno8Lw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "outputId": "906324fd-a50c-40fc-f239-a61df77a6f86"
      },
      "source": [
        "model = Net(HIDDENSIZE, NUM_CLASS, BATCHSIZE, NUMLAYERS)\n",
        "model.to(device)\n",
        "\n",
        "with open(\"model.pt\", \"rb\") as f:\n",
        "    SAVED_MODEL = torch.load(f)\n",
        "\n",
        "model.load_state_dict(SAVED_MODEL[\"state\"])\n",
        "\n",
        "model.eval()\n",
        "test_loss = 0\n",
        "cnt = 0\n",
        "test_correct = np.zeros(7)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "    for x, y in test_loader:\n",
        "        x = x.type(torch.FloatTensor).to(device)\n",
        "        y = y.to(device)\n",
        "        hidden = torch.zeros(NUMLAYERS, x.shape[0], HIDDENSIZE).to(device)\n",
        "        output, hidden = model(x, hidden)\n",
        "\n",
        "        loss = 0\n",
        "        for i in range(7):\n",
        "            predict = output[:, i]\n",
        "            target = y[:, i]\n",
        "            loss += loss_fn(predict, target)    #(16, 44), (16)\n",
        "        \n",
        "            \n",
        "        for i, prediction in enumerate(output.max(axis=2)[1]):\n",
        "            cnt += 1\n",
        "            for j in range(7):\n",
        "                if prediction[j].eq(y[i,j]).item():\n",
        "                    test_correct[j] +=1\n",
        "                    \n",
        "        test_loss += loss.item()\n",
        "    test_loss /= cnt\n",
        "    test_acc = test_correct.sum() / (cnt * 7)\n",
        "    \n",
        "print(\"total loss: %.4f, total acc: %.4f\"%(test_loss, test_acc) )\n",
        "print(\"\\n각 자리의 정확도\")\n",
        "print(test_correct / cnt)"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total loss: 0.2598, total acc: 0.8489\n",
            "\n",
            "각 자리의 정확도\n",
            "[0.95953757 0.93641618 0.26589595 0.95953757 0.94797688 0.94219653\n",
            " 0.93063584]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rr6VW_YJ1u0f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}