{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled","provenance":[],"private_outputs":true,"collapsed_sections":[],"authorship_tag":"ABX9TyM5OA5LN+6Gqq0zAHLqGQBq"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"RAQ1MNzMGSsb","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('./gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6UYrP84TGe4o","colab_type":"code","colab":{}},"source":["!ls"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ljbLiDF4wDLV","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Tp45Rd9EMqUo","colab_type":"text"},"source":[""]},{"cell_type":"code","metadata":{"id":"BxAK2oDoMYmv","colab_type":"code","colab":{}},"source":["class Net(nn.Module):\n","    def __init__(self):\n","        super(Net, self).__init__()\n","        self.fc1 = nn.Linear(784,512)\n","        self.fc2 = nn.Linear(512,256)\n","        self.fc3 = nn.Linear(256,128)\n","        self.fc4 = nn.Linear(128,64)\n","        self.fc5 = nn.Linear(64,32)\n","        self.fc6 = nn.Linear(32,10)\n","\n","    def forward(self, x):\n","        x = x.float()\n","        h1 = F.relu(self.fc1(x.view(-1, 784)))\n","        h2 = F.relu(self.fc2(h1))\n","        h3 = F.relu(self.fc3(h2))\n","        h4 = F.relu(self.fc4(h3))\n","        h5 = F.relu(self.fc5(h4))\n","        h6 = self.fc6(h5)\n","        return F.log_softmax(h6, dim=1)\n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"YF84vSm-SAxM","colab_type":"code","colab":{}},"source":["batch_size = 64\n","test_batch_size = 1000\n","epochs = 10\n","lr = .01\n","momentum = .5\n","seed = 1\n","log_interval = 200\n","\n","torch.manual_seed(seed)\n","device = torch.device(\"cuda\")\n","kwargs = {'num_workers': 1, 'pin_memory': True}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"idpQT215XgGF","colab_type":"code","colab":{}},"source":["transform = transforms.Compose([\n","                                transforms.ToTensor(),\n","                                transforms.Normalize((0.1307,), (0.3081,))])\n","train_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=True, download=True, transform=transform),\n","    batch_size = batch_size, shuffle=True, **kwargs)\n","\n","\n","\n","test_loader = torch.utils.data.DataLoader(\n","    datasets.MNIST('../data', train=False,download=True,transform=transform),\n","    batch_size=test_batch_size, shuffle=True, **kwargs\n",")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MkPQHkDVYTzo","colab_type":"code","colab":{}},"source":["model = Net()\n","optimizer = optim.SGD(model.parameters(), lr = lr, momentum=momentum)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Am-D80R9ZvP4","colab_type":"code","colab":{}},"source":["def train(log_interval, model, device, train_loader, optimizer, epoch):\n","    model.train()\n","    for batch_idx, (data, target) in enumerate(train_loader):\n","        data, target = data, target\n","        optimizer.zero_grad()\n","        output = model(data)\n","        loss = F.nll_loss(output, target)\n","        loss.backward()\n","        optimizer.step()\n","        if batch_idx%log_interval ==0:\n","            print('train epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                epoch, batch_idx*len(data), len(train_loader.dataset),\n","                100.*batch_idx / len(train_loader), loss.item()))\n","def test(log_interval, model, device, test_loader):\n","    model.eval()\n","    test_loss =0\n","    correct =0\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data, target\n","            ouput = model(data)\n","            test_loss += F.nll_loss(output, target, reduction='sum').item()\n","            pred = output.argmax(dim=1, keepdim=True)\n","            correct += pred.eq(target.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set : average loss: {:.4f}, accuract: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),\n","                                                                                  100.* correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jToYki3tby4w","colab_type":"code","colab":{}},"source":["for epoch in range(1, 11):\n","    train(log_interval, model, device, train_loader, optimizer, epoch)\n","    test(log_interval, model, device, test_loader)\n","\n","torch.save(model,'./model_mnist.pt')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"m5GLRmhoFa0p","colab_type":"text"},"source":["Model Load"]},{"cell_type":"code","metadata":{"id":"HzzGsJ9cFdcr","colab_type":"code","colab":{}},"source":["path = \"./model_mnist.pt\"\n","model = torch.load(path)\n","model.eval()\n","model()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1GpnSa0BJoeq","colab_type":"code","colab":{}},"source":["    test_loss =0\n","    correct =0\n","    \n","    for data, target in test_loader:\n","        data, target = data, target\n","        output = model(data)\n","        test_loss += F.nll_loss(output, target, reduction='sum').item()\n","        pred = output.argmax(dim=1, keepdim=True)\n","        correct += pred.eq(target.view_as(pred)).sum().item()\n","        break"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-qTWEzagK3p0","colab_type":"code","colab":{}},"source":["correct = 0\n","total = 0\n","model.eval()\n","with torch.no_grad():\n","  for image,label in test_loader:\n","      x = image#.to(device)\n","      y_= label#.to(device)\n","      output = model.forward(x)\n","      _,output_index = torch.max(output, 1)\n","      total += label.size(0)\n","      correct += (output_index == y_).sum().float()\n","  print(\"Accuracy of Test Data: {}%\".format(100.0*correct/total))"],"execution_count":null,"outputs":[]}]}
