{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Junhyung]cifar10.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "67du5hoorE-C",
        "colab_type": "text"
      },
      "source": [
        "# DATASET downlaod & unzip"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MR-8FLqPj1lO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 223
        },
        "outputId": "2aea496a-e53f-4664-81f2-74e72c6f3310"
      },
      "source": [
        "!wget 'https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz'"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-08-05 00:10:13--  https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "Resolving www.cs.toronto.edu (www.cs.toronto.edu)... 128.100.3.30\n",
            "Connecting to www.cs.toronto.edu (www.cs.toronto.edu)|128.100.3.30|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 170498071 (163M) [application/x-gzip]\n",
            "Saving to: ‘cifar-10-python.tar.gz.1’\n",
            "\n",
            "cifar-10-python.tar 100%[===================>] 162.60M  52.3MB/s    in 3.4s    \n",
            "\n",
            "2020-08-05 00:10:17 (47.6 MB/s) - ‘cifar-10-python.tar.gz.1’ saved [170498071/170498071]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twLcBvIhj49Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " import tarfile\n",
        "\n",
        " tarfile.open('cifar-10-python.tar.gz', 'r:gz').extractall()"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rv3C6KHumC4E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def unpickle(file):\n",
        "    import pickle\n",
        "    with open(file, 'rb') as fo:\n",
        "        dict = pickle.load(fo, encoding='bytes')\n",
        "    return dict"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV4h2lg_mUTV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_meta = unpickle('cifar-10-batches-py/batches.meta')"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVeOKM7qmYT-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "702aecbb-3401-42f1-c1e3-d6ec145fe2f7"
      },
      "source": [
        "print(batch_meta.keys())"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys([b'num_cases_per_batch', b'label_names', b'num_vis'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIdK4BrHnGdt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "8e865a3a-c167-43b0-b2be-5a5bc0a37a86"
      },
      "source": [
        "print(batch_meta[b'label_names'])"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[b'airplane', b'automobile', b'bird', b'cat', b'deer', b'dog', b'frog', b'horse', b'ship', b'truck']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZWdthlYneMl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "\n",
        "file_name = ['data_batch_1', 'data_batch_2', 'data_batch_3', 'data_batch_4', 'data_batch_5']\n",
        "label_tr = []\n",
        "img_tr = []\n",
        "data_path = 'cifar-10-batches-py'\n",
        "for i in file_name:\n",
        "    i = unpickle(os.path.join(data_path, i))\n",
        "    for a in i[b'labels']:\n",
        "        label_tr.append(a)\n",
        "    for b in i[b'data']:\n",
        "        img_tr.append(b)\n",
        "\n",
        "label_test = []\n",
        "img_test = []\n",
        "test_name = ['test_batch']\n",
        "for i in test_name:\n",
        "    i = unpickle(os.path.join(data_path, i))\n",
        "    for a in i[b'labels']:\n",
        "        label_test.append(a)\n",
        "    for b in i[b'data']:\n",
        "        img_test.append(b)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vc5YQ9VVuTsk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "outputId": "aeb2309e-9bfb-4f00-d3b6-93b227cb21c6"
      },
      "source": [
        "import random\n",
        "\n",
        "\n",
        "label_val = []\n",
        "img_val = []\n",
        "for _ in range(int(len(label_tr)*0.2)):\n",
        "    index = random.choice(range(1, len(label_tr)))\n",
        "    label_val.append(label_tr[index])\n",
        "    img_val.append(img_tr[index])\n",
        "    del label_tr[index]\n",
        "    del img_tr[index]    \n",
        "\n",
        "print(len(label_tr))\n",
        "print(len(img_tr))\n",
        "print(len(label_val))\n",
        "print(len(img_val))\n",
        "print(len(label_test))\n",
        "print(len(img_test))"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "40000\n",
            "40000\n",
            "10000\n",
            "10000\n",
            "10000\n",
            "10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_dFBMy4-w6Sp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4269e910-c22d-42e5-9219-c9bb50662828"
      },
      "source": [
        "print(img_tr[0].shape)\n",
        "print(type(label_tr[0]))"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3072,)\n",
            "<class 'int'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_OlW6c1xs0o",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "81c8a0df-5539-40d7-b260-3a98ae881511"
      },
      "source": [
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "\n",
        "%matplotlib inline\n",
        "imshow(img_tr[2].reshape(3, 32, 32).transpose(1, 2, 0))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f555cc63ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uvY6Nx5VtXSW",
        "colab_type": "text"
      },
      "source": [
        "# Dataset & Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuL4ZT_Qo9nt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "class Cifar10_DataSet(Dataset):\n",
        "    def __init__(self, labels, imgs):\n",
        "        self.labels = labels\n",
        "        self.imgs = imgs\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.imgs)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        img = np.asarray(self.imgs[index])\n",
        "        img = img.reshape(3, 32, 32)\n",
        "        label = np.asarray(self.labels[index])\n",
        "\n",
        "        return torch.from_numpy(img), torch.from_numpy(label)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6HL8ZHZs4BJl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#TODO: dataset transformer & augmentation 만들기\n",
        "from torchvision.transforms import Normalize\n",
        "transforms = Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tS8nwiqYq0bF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_tr = Cifar10_DataSet(label_tr, img_tr)\n",
        "dataset_val = Cifar10_DataSet(label_val, img_val)\n",
        "dataset_test = Cifar10_DataSet(label_test, img_test)"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aAjYrSLVy46q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_dataloader = DataLoader(dataset_tr, batch_size=512, shuffle=True)\n",
        "val_dataloader = DataLoader(dataset_val, batch_size=512, shuffle=True)\n",
        "test_dataloader = DataLoader(dataset_test, batch_size=512, shuffle=False)"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-TMRPTmK4GQV",
        "colab_type": "text"
      },
      "source": [
        "# Model & Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MojDZVlAzAN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 64, 5)\n",
        "        self.conv2 = nn.Conv2d(64, 64, 3)\n",
        "        self.conv3 = nn.Conv2d(64, 24, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(24 * 4 * 4, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x.float())))  # output = 64, 28/2, 28/2\n",
        "        x = self.pool(F.relu(self.conv2(x)))  # output = 64, 12/2, 12/2\n",
        "        x = F.relu(self.conv3(x))  # output = 24, 4, 4\n",
        "        x = x.view(-1, 24 * 4 * 4)\n",
        "        x = F.softmax(self.fc1(x), dim=1)\n",
        "        return x"
      ],
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Armd3vBJ3beL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "outputId": "9a48065a-3a8c-4f59-a3e9-ce18cf7e189c"
      },
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available)\n",
        "device = torch.device(\"cuda:0\")"
      ],
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<function is_available at 0x7f55664a9488>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rgdAmvxW24xY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ac6454f-2f3b-4d58-9489-d46984f1bbae"
      },
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "# import queue\n",
        "\n",
        "model = Model()\n",
        "model = model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "count = 0\n",
        "val_loss_que = []\n",
        "for epoch in range(1000):\n",
        "    train_loss = 0\n",
        "    for i, (inputs, labels) in enumerate(tr_dataloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "    val_loss = 0\n",
        "    for i, data in enumerate(val_dataloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        loss = criterion(outputs, labels)\n",
        "        val_loss += loss.item()\n",
        "\n",
        "    train_loss /= len(tr_dataloader)\n",
        "    val_loss /= len(val_dataloader)\n",
        "    val_loss_que.append(val_loss)\n",
        "    \n",
        "    if epoch+1 >= 20:\n",
        "        # print(len(val_loss_que))\n",
        "        pre_val = sum(val_loss_que)/20\n",
        "        if pre_val <= val_loss:\n",
        "            count += 1\n",
        "            if count ==5:\n",
        "                print('early stopping')\n",
        "                break    \n",
        "        else:\n",
        "            count = 0\n",
        "\n",
        "        del val_loss_que[0]\n",
        "        print('[{} epoch] tr_loss: {:.4f}  val_loss: {:.4f}  pre_mean val_loss:  {:.4f}  early stopping ccount:  {}'.format(epoch + 1, train_loss, val_loss, pre_val, count))\n",
        "    else:\n",
        "        print('[{} epoch] tr_loss: {:.4f}  val_loss: {:.4f}'.format(epoch + 1, train_loss, val_loss))\n",
        "        \n",
        "    "
      ],
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 epoch] tr_loss: 2.2834  val_loss: 2.2271\n",
            "[2 epoch] tr_loss: 2.2372  val_loss: 2.1905\n",
            "[3 epoch] tr_loss: 2.1669  val_loss: 2.1187\n",
            "[4 epoch] tr_loss: 2.1028  val_loss: 2.0704\n",
            "[5 epoch] tr_loss: 2.0450  val_loss: 1.9928\n",
            "[6 epoch] tr_loss: 2.0229  val_loss: 1.9127\n",
            "[7 epoch] tr_loss: 2.0066  val_loss: 1.9503\n",
            "[8 epoch] tr_loss: 1.9898  val_loss: 1.9615\n",
            "[9 epoch] tr_loss: 1.9740  val_loss: 1.8243\n",
            "[10 epoch] tr_loss: 1.9671  val_loss: 1.9565\n",
            "[11 epoch] tr_loss: 1.9535  val_loss: 1.9442\n",
            "[12 epoch] tr_loss: 1.9444  val_loss: 1.8198\n",
            "[13 epoch] tr_loss: 1.9388  val_loss: 1.9298\n",
            "[14 epoch] tr_loss: 1.9307  val_loss: 1.9394\n",
            "[15 epoch] tr_loss: 1.9274  val_loss: 1.9210\n",
            "[16 epoch] tr_loss: 1.9186  val_loss: 1.8816\n",
            "[17 epoch] tr_loss: 1.9171  val_loss: 1.8614\n",
            "[18 epoch] tr_loss: 1.9110  val_loss: 1.8717\n",
            "[19 epoch] tr_loss: 1.9079  val_loss: 1.8403\n",
            "[20 epoch] tr_loss: 1.9015  val_loss: 1.8438  pre_mean val_loss:  1.9529  early stopping ccount:  0\n",
            "[21 epoch] tr_loss: 1.8991  val_loss: 1.7925  pre_mean val_loss:  1.9312  early stopping ccount:  0\n",
            "[22 epoch] tr_loss: 1.8942  val_loss: 1.8365  pre_mean val_loss:  1.9135  early stopping ccount:  0\n",
            "[23 epoch] tr_loss: 1.8908  val_loss: 1.9171  pre_mean val_loss:  1.9034  early stopping ccount:  1\n",
            "[24 epoch] tr_loss: 1.8905  val_loss: 1.8205  pre_mean val_loss:  1.8909  early stopping ccount:  0\n",
            "[25 epoch] tr_loss: 1.8808  val_loss: 1.7697  pre_mean val_loss:  1.8797  early stopping ccount:  0\n",
            "[26 epoch] tr_loss: 1.8812  val_loss: 1.8470  pre_mean val_loss:  1.8764  early stopping ccount:  0\n",
            "[27 epoch] tr_loss: 1.8771  val_loss: 1.8451  pre_mean val_loss:  1.8712  early stopping ccount:  0\n",
            "[28 epoch] tr_loss: 1.8770  val_loss: 1.9987  pre_mean val_loss:  1.8730  early stopping ccount:  1\n",
            "[29 epoch] tr_loss: 1.8724  val_loss: 1.8912  pre_mean val_loss:  1.8764  early stopping ccount:  2\n",
            "[30 epoch] tr_loss: 1.8688  val_loss: 1.8675  pre_mean val_loss:  1.8719  early stopping ccount:  0\n",
            "[31 epoch] tr_loss: 1.8643  val_loss: 1.7647  pre_mean val_loss:  1.8630  early stopping ccount:  0\n",
            "[32 epoch] tr_loss: 1.8625  val_loss: 1.8271  pre_mean val_loss:  1.8633  early stopping ccount:  0\n",
            "[33 epoch] tr_loss: 1.8580  val_loss: 1.8067  pre_mean val_loss:  1.8572  early stopping ccount:  0\n",
            "[34 epoch] tr_loss: 1.8584  val_loss: 1.8852  pre_mean val_loss:  1.8545  early stopping ccount:  1\n",
            "[35 epoch] tr_loss: 1.8548  val_loss: 1.7260  pre_mean val_loss:  1.8447  early stopping ccount:  0\n",
            "[36 epoch] tr_loss: 1.8517  val_loss: 1.7195  pre_mean val_loss:  1.8366  early stopping ccount:  0\n",
            "[37 epoch] tr_loss: 1.8532  val_loss: 1.9215  pre_mean val_loss:  1.8396  early stopping ccount:  1\n",
            "[38 epoch] tr_loss: 1.8495  val_loss: 1.6971  pre_mean val_loss:  1.8309  early stopping ccount:  0\n",
            "[39 epoch] tr_loss: 1.8454  val_loss: 1.8691  pre_mean val_loss:  1.8323  early stopping ccount:  1\n",
            "[40 epoch] tr_loss: 1.8432  val_loss: 1.8354  pre_mean val_loss:  1.8319  early stopping ccount:  2\n",
            "[41 epoch] tr_loss: 1.8384  val_loss: 1.7655  pre_mean val_loss:  1.8306  early stopping ccount:  0\n",
            "[42 epoch] tr_loss: 1.8366  val_loss: 1.8672  pre_mean val_loss:  1.8321  early stopping ccount:  1\n",
            "[43 epoch] tr_loss: 1.8347  val_loss: 1.7374  pre_mean val_loss:  1.8231  early stopping ccount:  0\n",
            "[44 epoch] tr_loss: 1.8341  val_loss: 1.8096  pre_mean val_loss:  1.8226  early stopping ccount:  0\n",
            "[45 epoch] tr_loss: 1.8353  val_loss: 1.7601  pre_mean val_loss:  1.8221  early stopping ccount:  0\n",
            "[46 epoch] tr_loss: 1.8302  val_loss: 1.8185  pre_mean val_loss:  1.8207  early stopping ccount:  0\n",
            "[47 epoch] tr_loss: 1.8295  val_loss: 1.7801  pre_mean val_loss:  1.8174  early stopping ccount:  0\n",
            "[48 epoch] tr_loss: 1.8306  val_loss: 1.8056  pre_mean val_loss:  1.8077  early stopping ccount:  0\n",
            "[49 epoch] tr_loss: 1.8311  val_loss: 1.8297  pre_mean val_loss:  1.8047  early stopping ccount:  1\n",
            "[50 epoch] tr_loss: 1.8205  val_loss: 1.7306  pre_mean val_loss:  1.7978  early stopping ccount:  0\n",
            "[51 epoch] tr_loss: 1.8239  val_loss: 1.8266  pre_mean val_loss:  1.8009  early stopping ccount:  1\n",
            "[52 epoch] tr_loss: 1.8191  val_loss: 1.8180  pre_mean val_loss:  1.8005  early stopping ccount:  2\n",
            "[53 epoch] tr_loss: 1.8174  val_loss: 1.7809  pre_mean val_loss:  1.7992  early stopping ccount:  0\n",
            "[54 epoch] tr_loss: 1.8148  val_loss: 1.6755  pre_mean val_loss:  1.7887  early stopping ccount:  0\n",
            "[55 epoch] tr_loss: 1.8154  val_loss: 1.7879  pre_mean val_loss:  1.7918  early stopping ccount:  0\n",
            "[56 epoch] tr_loss: 1.8122  val_loss: 1.7218  pre_mean val_loss:  1.7919  early stopping ccount:  0\n",
            "[57 epoch] tr_loss: 1.8146  val_loss: 1.8243  pre_mean val_loss:  1.7870  early stopping ccount:  1\n",
            "[58 epoch] tr_loss: 1.8118  val_loss: 1.7773  pre_mean val_loss:  1.7911  early stopping ccount:  0\n",
            "[59 epoch] tr_loss: 1.8111  val_loss: 1.8251  pre_mean val_loss:  1.7889  early stopping ccount:  1\n",
            "[60 epoch] tr_loss: 1.8063  val_loss: 1.7637  pre_mean val_loss:  1.7853  early stopping ccount:  0\n",
            "[61 epoch] tr_loss: 1.8037  val_loss: 1.7892  pre_mean val_loss:  1.7865  early stopping ccount:  1\n",
            "[62 epoch] tr_loss: 1.8014  val_loss: 1.8940  pre_mean val_loss:  1.7878  early stopping ccount:  2\n",
            "[63 epoch] tr_loss: 1.7989  val_loss: 1.6882  pre_mean val_loss:  1.7853  early stopping ccount:  0\n",
            "[64 epoch] tr_loss: 1.8039  val_loss: 1.8661  pre_mean val_loss:  1.7882  early stopping ccount:  1\n",
            "[65 epoch] tr_loss: 1.7982  val_loss: 1.8015  pre_mean val_loss:  1.7902  early stopping ccount:  2\n",
            "[66 epoch] tr_loss: 1.7983  val_loss: 1.7063  pre_mean val_loss:  1.7846  early stopping ccount:  0\n",
            "[67 epoch] tr_loss: 1.7978  val_loss: 1.8299  pre_mean val_loss:  1.7871  early stopping ccount:  1\n",
            "[68 epoch] tr_loss: 1.7962  val_loss: 1.7673  pre_mean val_loss:  1.7852  early stopping ccount:  0\n",
            "[69 epoch] tr_loss: 1.7944  val_loss: 1.7746  pre_mean val_loss:  1.7824  early stopping ccount:  0\n",
            "[70 epoch] tr_loss: 1.7933  val_loss: 1.7953  pre_mean val_loss:  1.7857  early stopping ccount:  1\n",
            "[71 epoch] tr_loss: 1.7934  val_loss: 1.7974  pre_mean val_loss:  1.7842  early stopping ccount:  2\n",
            "[72 epoch] tr_loss: 1.7901  val_loss: 1.7320  pre_mean val_loss:  1.7799  early stopping ccount:  0\n",
            "[73 epoch] tr_loss: 1.7897  val_loss: 1.7870  pre_mean val_loss:  1.7802  early stopping ccount:  1\n",
            "[74 epoch] tr_loss: 1.7862  val_loss: 1.7153  pre_mean val_loss:  1.7822  early stopping ccount:  0\n",
            "[75 epoch] tr_loss: 1.7844  val_loss: 1.8075  pre_mean val_loss:  1.7832  early stopping ccount:  1\n",
            "[76 epoch] tr_loss: 1.7823  val_loss: 1.6309  pre_mean val_loss:  1.7786  early stopping ccount:  0\n",
            "[77 epoch] tr_loss: 1.7835  val_loss: 1.7521  pre_mean val_loss:  1.7750  early stopping ccount:  0\n",
            "[78 epoch] tr_loss: 1.7858  val_loss: 1.8575  pre_mean val_loss:  1.7790  early stopping ccount:  1\n",
            "[79 epoch] tr_loss: 1.7793  val_loss: 1.7044  pre_mean val_loss:  1.7730  early stopping ccount:  0\n",
            "[80 epoch] tr_loss: 1.7822  val_loss: 1.8247  pre_mean val_loss:  1.7761  early stopping ccount:  1\n",
            "[81 epoch] tr_loss: 1.7801  val_loss: 1.7984  pre_mean val_loss:  1.7765  early stopping ccount:  2\n",
            "[82 epoch] tr_loss: 1.7778  val_loss: 1.7126  pre_mean val_loss:  1.7675  early stopping ccount:  0\n",
            "[83 epoch] tr_loss: 1.7805  val_loss: 1.7329  pre_mean val_loss:  1.7697  early stopping ccount:  0\n",
            "[84 epoch] tr_loss: 1.7768  val_loss: 1.8018  pre_mean val_loss:  1.7665  early stopping ccount:  1\n",
            "[85 epoch] tr_loss: 1.7754  val_loss: 1.8542  pre_mean val_loss:  1.7691  early stopping ccount:  2\n",
            "[86 epoch] tr_loss: 1.7738  val_loss: 1.7642  pre_mean val_loss:  1.7720  early stopping ccount:  0\n",
            "[87 epoch] tr_loss: 1.7786  val_loss: 1.6818  pre_mean val_loss:  1.7646  early stopping ccount:  0\n",
            "[88 epoch] tr_loss: 1.7744  val_loss: 1.7775  pre_mean val_loss:  1.7651  early stopping ccount:  1\n",
            "[89 epoch] tr_loss: 1.7740  val_loss: 1.7492  pre_mean val_loss:  1.7638  early stopping ccount:  0\n",
            "[90 epoch] tr_loss: 1.7683  val_loss: 1.7288  pre_mean val_loss:  1.7605  early stopping ccount:  0\n",
            "[91 epoch] tr_loss: 1.7681  val_loss: 1.7656  pre_mean val_loss:  1.7589  early stopping ccount:  1\n",
            "[92 epoch] tr_loss: 1.7676  val_loss: 1.7515  pre_mean val_loss:  1.7599  early stopping ccount:  0\n",
            "[93 epoch] tr_loss: 1.7651  val_loss: 1.7132  pre_mean val_loss:  1.7562  early stopping ccount:  0\n",
            "[94 epoch] tr_loss: 1.7681  val_loss: 1.8796  pre_mean val_loss:  1.7644  early stopping ccount:  1\n",
            "[95 epoch] tr_loss: 1.7671  val_loss: 1.7444  pre_mean val_loss:  1.7613  early stopping ccount:  0\n",
            "[96 epoch] tr_loss: 1.7660  val_loss: 1.7525  pre_mean val_loss:  1.7673  early stopping ccount:  0\n",
            "[97 epoch] tr_loss: 1.7635  val_loss: 1.7606  pre_mean val_loss:  1.7678  early stopping ccount:  0\n",
            "[98 epoch] tr_loss: 1.7616  val_loss: 1.7786  pre_mean val_loss:  1.7638  early stopping ccount:  1\n",
            "[99 epoch] tr_loss: 1.7605  val_loss: 1.7573  pre_mean val_loss:  1.7665  early stopping ccount:  0\n",
            "[100 epoch] tr_loss: 1.7619  val_loss: 1.7433  pre_mean val_loss:  1.7624  early stopping ccount:  0\n",
            "[101 epoch] tr_loss: 1.7600  val_loss: 1.7137  pre_mean val_loss:  1.7582  early stopping ccount:  0\n",
            "[102 epoch] tr_loss: 1.7585  val_loss: 1.6051  pre_mean val_loss:  1.7528  early stopping ccount:  0\n",
            "[103 epoch] tr_loss: 1.7586  val_loss: 1.8166  pre_mean val_loss:  1.7570  early stopping ccount:  1\n",
            "[104 epoch] tr_loss: 1.7558  val_loss: 1.7030  pre_mean val_loss:  1.7520  early stopping ccount:  0\n",
            "[105 epoch] tr_loss: 1.7557  val_loss: 1.6940  pre_mean val_loss:  1.7440  early stopping ccount:  0\n",
            "[106 epoch] tr_loss: 1.7557  val_loss: 1.8316  pre_mean val_loss:  1.7474  early stopping ccount:  1\n",
            "[107 epoch] tr_loss: 1.7543  val_loss: 1.7147  pre_mean val_loss:  1.7490  early stopping ccount:  0\n",
            "[108 epoch] tr_loss: 1.7531  val_loss: 1.6878  pre_mean val_loss:  1.7446  early stopping ccount:  0\n",
            "[109 epoch] tr_loss: 1.7536  val_loss: 1.7783  pre_mean val_loss:  1.7460  early stopping ccount:  1\n",
            "[110 epoch] tr_loss: 1.7502  val_loss: 1.7059  pre_mean val_loss:  1.7449  early stopping ccount:  0\n",
            "[111 epoch] tr_loss: 1.7501  val_loss: 1.7626  pre_mean val_loss:  1.7447  early stopping ccount:  1\n",
            "[112 epoch] tr_loss: 1.7490  val_loss: 1.7313  pre_mean val_loss:  1.7437  early stopping ccount:  0\n",
            "[113 epoch] tr_loss: 1.7495  val_loss: 1.7254  pre_mean val_loss:  1.7443  early stopping ccount:  0\n",
            "[114 epoch] tr_loss: 1.7500  val_loss: 1.7129  pre_mean val_loss:  1.7360  early stopping ccount:  0\n",
            "[115 epoch] tr_loss: 1.7522  val_loss: 1.8018  pre_mean val_loss:  1.7388  early stopping ccount:  1\n",
            "[116 epoch] tr_loss: 1.7483  val_loss: 1.6759  pre_mean val_loss:  1.7350  early stopping ccount:  0\n",
            "[117 epoch] tr_loss: 1.7463  val_loss: 1.7817  pre_mean val_loss:  1.7361  early stopping ccount:  1\n",
            "[118 epoch] tr_loss: 1.7476  val_loss: 1.7530  pre_mean val_loss:  1.7348  early stopping ccount:  2\n",
            "[119 epoch] tr_loss: 1.7439  val_loss: 1.7851  pre_mean val_loss:  1.7362  early stopping ccount:  3\n",
            "[120 epoch] tr_loss: 1.7431  val_loss: 1.7118  pre_mean val_loss:  1.7346  early stopping ccount:  0\n",
            "[121 epoch] tr_loss: 1.7429  val_loss: 1.7171  pre_mean val_loss:  1.7348  early stopping ccount:  0\n",
            "[122 epoch] tr_loss: 1.7467  val_loss: 1.7605  pre_mean val_loss:  1.7426  early stopping ccount:  1\n",
            "[123 epoch] tr_loss: 1.7444  val_loss: 1.7615  pre_mean val_loss:  1.7398  early stopping ccount:  2\n",
            "[124 epoch] tr_loss: 1.7451  val_loss: 1.7168  pre_mean val_loss:  1.7405  early stopping ccount:  0\n",
            "[125 epoch] tr_loss: 1.7412  val_loss: 1.6913  pre_mean val_loss:  1.7404  early stopping ccount:  0\n",
            "[126 epoch] tr_loss: 1.7403  val_loss: 1.7281  pre_mean val_loss:  1.7352  early stopping ccount:  0\n",
            "[127 epoch] tr_loss: 1.7392  val_loss: 1.7270  pre_mean val_loss:  1.7358  early stopping ccount:  0\n",
            "[128 epoch] tr_loss: 1.7429  val_loss: 1.8188  pre_mean val_loss:  1.7423  early stopping ccount:  1\n",
            "[129 epoch] tr_loss: 1.7392  val_loss: 1.7047  pre_mean val_loss:  1.7387  early stopping ccount:  0\n",
            "[130 epoch] tr_loss: 1.7364  val_loss: 1.6407  pre_mean val_loss:  1.7354  early stopping ccount:  0\n",
            "[131 epoch] tr_loss: 1.7383  val_loss: 1.7148  pre_mean val_loss:  1.7330  early stopping ccount:  0\n",
            "[132 epoch] tr_loss: 1.7375  val_loss: 1.7180  pre_mean val_loss:  1.7324  early stopping ccount:  0\n",
            "[133 epoch] tr_loss: 1.7347  val_loss: 1.7620  pre_mean val_loss:  1.7342  early stopping ccount:  1\n",
            "[134 epoch] tr_loss: 1.7350  val_loss: 1.6968  pre_mean val_loss:  1.7334  early stopping ccount:  0\n",
            "[135 epoch] tr_loss: 1.7317  val_loss: 1.6719  pre_mean val_loss:  1.7269  early stopping ccount:  0\n",
            "[136 epoch] tr_loss: 1.7320  val_loss: 1.6184  pre_mean val_loss:  1.7240  early stopping ccount:  0\n",
            "[137 epoch] tr_loss: 1.7328  val_loss: 1.6838  pre_mean val_loss:  1.7191  early stopping ccount:  0\n",
            "[138 epoch] tr_loss: 1.7338  val_loss: 1.7612  pre_mean val_loss:  1.7195  early stopping ccount:  1\n",
            "[139 epoch] tr_loss: 1.7325  val_loss: 1.7326  pre_mean val_loss:  1.7169  early stopping ccount:  2\n",
            "[140 epoch] tr_loss: 1.7324  val_loss: 1.7085  pre_mean val_loss:  1.7167  early stopping ccount:  0\n",
            "[141 epoch] tr_loss: 1.7297  val_loss: 1.6543  pre_mean val_loss:  1.7136  early stopping ccount:  0\n",
            "[142 epoch] tr_loss: 1.7303  val_loss: 1.6556  pre_mean val_loss:  1.7083  early stopping ccount:  0\n",
            "[143 epoch] tr_loss: 1.7296  val_loss: 1.7306  pre_mean val_loss:  1.7068  early stopping ccount:  1\n",
            "[144 epoch] tr_loss: 1.7271  val_loss: 1.6366  pre_mean val_loss:  1.7028  early stopping ccount:  0\n",
            "[145 epoch] tr_loss: 1.7301  val_loss: 1.6803  pre_mean val_loss:  1.7022  early stopping ccount:  0\n",
            "[146 epoch] tr_loss: 1.7319  val_loss: 1.7000  pre_mean val_loss:  1.7008  early stopping ccount:  0\n",
            "[147 epoch] tr_loss: 1.7287  val_loss: 1.7576  pre_mean val_loss:  1.7024  early stopping ccount:  1\n",
            "[148 epoch] tr_loss: 1.7259  val_loss: 1.6061  pre_mean val_loss:  1.6917  early stopping ccount:  0\n",
            "[149 epoch] tr_loss: 1.7315  val_loss: 1.8528  pre_mean val_loss:  1.6991  early stopping ccount:  1\n",
            "[150 epoch] tr_loss: 1.7275  val_loss: 1.7196  pre_mean val_loss:  1.7031  early stopping ccount:  2\n",
            "[151 epoch] tr_loss: 1.7289  val_loss: 1.6826  pre_mean val_loss:  1.7015  early stopping ccount:  0\n",
            "[152 epoch] tr_loss: 1.7235  val_loss: 1.6713  pre_mean val_loss:  1.6991  early stopping ccount:  0\n",
            "[153 epoch] tr_loss: 1.7267  val_loss: 1.7584  pre_mean val_loss:  1.6989  early stopping ccount:  1\n",
            "[154 epoch] tr_loss: 1.7274  val_loss: 1.7518  pre_mean val_loss:  1.7017  early stopping ccount:  2\n",
            "[155 epoch] tr_loss: 1.7269  val_loss: 1.7734  pre_mean val_loss:  1.7068  early stopping ccount:  3\n",
            "[156 epoch] tr_loss: 1.7221  val_loss: 1.6255  pre_mean val_loss:  1.7071  early stopping ccount:  0\n",
            "[157 epoch] tr_loss: 1.7243  val_loss: 1.7082  pre_mean val_loss:  1.7084  early stopping ccount:  0\n",
            "[158 epoch] tr_loss: 1.7241  val_loss: 1.7486  pre_mean val_loss:  1.7077  early stopping ccount:  1\n",
            "[159 epoch] tr_loss: 1.7212  val_loss: 1.5884  pre_mean val_loss:  1.7005  early stopping ccount:  0\n",
            "[160 epoch] tr_loss: 1.7205  val_loss: 1.7303  pre_mean val_loss:  1.7016  early stopping ccount:  1\n",
            "[161 epoch] tr_loss: 1.7226  val_loss: 1.6797  pre_mean val_loss:  1.7029  early stopping ccount:  0\n",
            "[162 epoch] tr_loss: 1.7219  val_loss: 1.7169  pre_mean val_loss:  1.7059  early stopping ccount:  1\n",
            "[163 epoch] tr_loss: 1.7249  val_loss: 1.7307  pre_mean val_loss:  1.7059  early stopping ccount:  2\n",
            "[164 epoch] tr_loss: 1.7187  val_loss: 1.6361  pre_mean val_loss:  1.7059  early stopping ccount:  0\n",
            "[165 epoch] tr_loss: 1.7210  val_loss: 1.7138  pre_mean val_loss:  1.7076  early stopping ccount:  1\n",
            "[166 epoch] tr_loss: 1.7211  val_loss: 1.7081  pre_mean val_loss:  1.7080  early stopping ccount:  2\n",
            "[167 epoch] tr_loss: 1.7199  val_loss: 1.6596  pre_mean val_loss:  1.7031  early stopping ccount:  0\n",
            "[168 epoch] tr_loss: 1.7224  val_loss: 1.6256  pre_mean val_loss:  1.7041  early stopping ccount:  0\n",
            "[169 epoch] tr_loss: 1.7181  val_loss: 1.7402  pre_mean val_loss:  1.6984  early stopping ccount:  1\n",
            "[170 epoch] tr_loss: 1.7158  val_loss: 1.7159  pre_mean val_loss:  1.6983  early stopping ccount:  2\n",
            "[171 epoch] tr_loss: 1.7156  val_loss: 1.6554  pre_mean val_loss:  1.6969  early stopping ccount:  0\n",
            "[172 epoch] tr_loss: 1.7187  val_loss: 1.7559  pre_mean val_loss:  1.7011  early stopping ccount:  1\n",
            "[173 epoch] tr_loss: 1.7184  val_loss: 1.7124  pre_mean val_loss:  1.6988  early stopping ccount:  2\n",
            "[174 epoch] tr_loss: 1.7132  val_loss: 1.6556  pre_mean val_loss:  1.6940  early stopping ccount:  0\n",
            "[175 epoch] tr_loss: 1.7137  val_loss: 1.7288  pre_mean val_loss:  1.6918  early stopping ccount:  1\n",
            "[176 epoch] tr_loss: 1.7139  val_loss: 1.5875  pre_mean val_loss:  1.6899  early stopping ccount:  0\n",
            "[177 epoch] tr_loss: 1.7150  val_loss: 1.7258  pre_mean val_loss:  1.6908  early stopping ccount:  1\n",
            "[178 epoch] tr_loss: 1.7146  val_loss: 1.6926  pre_mean val_loss:  1.6880  early stopping ccount:  2\n",
            "[179 epoch] tr_loss: 1.7126  val_loss: 1.6984  pre_mean val_loss:  1.6935  early stopping ccount:  3\n",
            "[180 epoch] tr_loss: 1.7123  val_loss: 1.6673  pre_mean val_loss:  1.6903  early stopping ccount:  0\n",
            "[181 epoch] tr_loss: 1.7131  val_loss: 1.7221  pre_mean val_loss:  1.6924  early stopping ccount:  1\n",
            "[182 epoch] tr_loss: 1.7112  val_loss: 1.6531  pre_mean val_loss:  1.6892  early stopping ccount:  0\n",
            "[183 epoch] tr_loss: 1.7160  val_loss: 1.6661  pre_mean val_loss:  1.6860  early stopping ccount:  0\n",
            "[184 epoch] tr_loss: 1.7136  val_loss: 1.5868  pre_mean val_loss:  1.6835  early stopping ccount:  0\n",
            "[185 epoch] tr_loss: 1.7093  val_loss: 1.6365  pre_mean val_loss:  1.6797  early stopping ccount:  0\n",
            "[186 epoch] tr_loss: 1.7110  val_loss: 1.6718  pre_mean val_loss:  1.6779  early stopping ccount:  0\n",
            "[187 epoch] tr_loss: 1.7109  val_loss: 1.6984  pre_mean val_loss:  1.6798  early stopping ccount:  1\n",
            "[188 epoch] tr_loss: 1.7106  val_loss: 1.7271  pre_mean val_loss:  1.6849  early stopping ccount:  2\n",
            "[189 epoch] tr_loss: 1.7094  val_loss: 1.6510  pre_mean val_loss:  1.6804  early stopping ccount:  0\n",
            "[190 epoch] tr_loss: 1.7113  val_loss: 1.6999  pre_mean val_loss:  1.6796  early stopping ccount:  1\n",
            "[191 epoch] tr_loss: 1.7088  val_loss: 1.6806  pre_mean val_loss:  1.6809  early stopping ccount:  0\n",
            "[192 epoch] tr_loss: 1.7103  val_loss: 1.6648  pre_mean val_loss:  1.6763  early stopping ccount:  0\n",
            "[193 epoch] tr_loss: 1.7092  val_loss: 1.7620  pre_mean val_loss:  1.6788  early stopping ccount:  1\n",
            "[194 epoch] tr_loss: 1.7089  val_loss: 1.7437  pre_mean val_loss:  1.6832  early stopping ccount:  2\n",
            "[195 epoch] tr_loss: 1.7093  val_loss: 1.7736  pre_mean val_loss:  1.6855  early stopping ccount:  3\n",
            "[196 epoch] tr_loss: 1.7063  val_loss: 1.6670  pre_mean val_loss:  1.6894  early stopping ccount:  0\n",
            "[197 epoch] tr_loss: 1.7058  val_loss: 1.6984  pre_mean val_loss:  1.6881  early stopping ccount:  1\n",
            "[198 epoch] tr_loss: 1.7088  val_loss: 1.8481  pre_mean val_loss:  1.6958  early stopping ccount:  2\n",
            "[199 epoch] tr_loss: 1.7069  val_loss: 1.6334  pre_mean val_loss:  1.6926  early stopping ccount:  0\n",
            "[200 epoch] tr_loss: 1.7055  val_loss: 1.7016  pre_mean val_loss:  1.6943  early stopping ccount:  1\n",
            "[201 epoch] tr_loss: 1.7084  val_loss: 1.7673  pre_mean val_loss:  1.6966  early stopping ccount:  2\n",
            "[202 epoch] tr_loss: 1.7216  val_loss: 1.7151  pre_mean val_loss:  1.6997  early stopping ccount:  3\n",
            "[203 epoch] tr_loss: 1.7111  val_loss: 1.6961  pre_mean val_loss:  1.7012  early stopping ccount:  0\n",
            "[204 epoch] tr_loss: 1.7079  val_loss: 1.7573  pre_mean val_loss:  1.7097  early stopping ccount:  1\n",
            "[205 epoch] tr_loss: 1.7110  val_loss: 1.6477  pre_mean val_loss:  1.7103  early stopping ccount:  0\n",
            "[206 epoch] tr_loss: 1.7039  val_loss: 1.7113  pre_mean val_loss:  1.7122  early stopping ccount:  0\n",
            "[207 epoch] tr_loss: 1.6951  val_loss: 1.6252  pre_mean val_loss:  1.7086  early stopping ccount:  0\n",
            "[208 epoch] tr_loss: 1.6866  val_loss: 1.6410  pre_mean val_loss:  1.7043  early stopping ccount:  0\n",
            "[209 epoch] tr_loss: 1.6832  val_loss: 1.6647  pre_mean val_loss:  1.7049  early stopping ccount:  0\n",
            "[210 epoch] tr_loss: 1.6787  val_loss: 1.7015  pre_mean val_loss:  1.7050  early stopping ccount:  0\n",
            "[211 epoch] tr_loss: 1.6760  val_loss: 1.6379  pre_mean val_loss:  1.7029  early stopping ccount:  0\n",
            "[212 epoch] tr_loss: 1.6723  val_loss: 1.6327  pre_mean val_loss:  1.7013  early stopping ccount:  0\n",
            "[213 epoch] tr_loss: 1.6713  val_loss: 1.6099  pre_mean val_loss:  1.6937  early stopping ccount:  0\n",
            "[214 epoch] tr_loss: 1.6685  val_loss: 1.6505  pre_mean val_loss:  1.6890  early stopping ccount:  0\n",
            "[215 epoch] tr_loss: 1.6660  val_loss: 1.6207  pre_mean val_loss:  1.6814  early stopping ccount:  0\n",
            "[216 epoch] tr_loss: 1.6647  val_loss: 1.5870  pre_mean val_loss:  1.6774  early stopping ccount:  0\n",
            "[217 epoch] tr_loss: 1.6659  val_loss: 1.6367  pre_mean val_loss:  1.6743  early stopping ccount:  0\n",
            "[218 epoch] tr_loss: 1.6671  val_loss: 1.5458  pre_mean val_loss:  1.6592  early stopping ccount:  0\n",
            "[219 epoch] tr_loss: 1.6647  val_loss: 1.6282  pre_mean val_loss:  1.6589  early stopping ccount:  0\n",
            "[220 epoch] tr_loss: 1.6614  val_loss: 1.6498  pre_mean val_loss:  1.6563  early stopping ccount:  0\n",
            "[221 epoch] tr_loss: 1.6610  val_loss: 1.6829  pre_mean val_loss:  1.6521  early stopping ccount:  1\n",
            "[222 epoch] tr_loss: 1.6608  val_loss: 1.7516  pre_mean val_loss:  1.6539  early stopping ccount:  2\n",
            "[223 epoch] tr_loss: 1.6584  val_loss: 1.5823  pre_mean val_loss:  1.6482  early stopping ccount:  0\n",
            "[224 epoch] tr_loss: 1.6631  val_loss: 1.6747  pre_mean val_loss:  1.6441  early stopping ccount:  1\n",
            "[225 epoch] tr_loss: 1.6576  val_loss: 1.7278  pre_mean val_loss:  1.6481  early stopping ccount:  2\n",
            "[226 epoch] tr_loss: 1.6590  val_loss: 1.7286  pre_mean val_loss:  1.6490  early stopping ccount:  3\n",
            "[227 epoch] tr_loss: 1.6565  val_loss: 1.5914  pre_mean val_loss:  1.6473  early stopping ccount:  0\n",
            "[228 epoch] tr_loss: 1.6545  val_loss: 1.6448  pre_mean val_loss:  1.6475  early stopping ccount:  0\n",
            "[229 epoch] tr_loss: 1.6544  val_loss: 1.7489  pre_mean val_loss:  1.6517  early stopping ccount:  1\n",
            "[230 epoch] tr_loss: 1.6537  val_loss: 1.6449  pre_mean val_loss:  1.6489  early stopping ccount:  0\n",
            "[231 epoch] tr_loss: 1.6530  val_loss: 1.6184  pre_mean val_loss:  1.6479  early stopping ccount:  0\n",
            "[232 epoch] tr_loss: 1.6547  val_loss: 1.7283  pre_mean val_loss:  1.6527  early stopping ccount:  1\n",
            "[233 epoch] tr_loss: 1.6516  val_loss: 1.6841  pre_mean val_loss:  1.6564  early stopping ccount:  2\n",
            "[234 epoch] tr_loss: 1.6523  val_loss: 1.6469  pre_mean val_loss:  1.6562  early stopping ccount:  0\n",
            "[235 epoch] tr_loss: 1.6545  val_loss: 1.7568  pre_mean val_loss:  1.6630  early stopping ccount:  1\n",
            "[236 epoch] tr_loss: 1.6544  val_loss: 1.6481  pre_mean val_loss:  1.6661  early stopping ccount:  0\n",
            "[237 epoch] tr_loss: 1.6523  val_loss: 1.7192  pre_mean val_loss:  1.6702  early stopping ccount:  1\n",
            "[238 epoch] tr_loss: 1.6500  val_loss: 1.6092  pre_mean val_loss:  1.6734  early stopping ccount:  0\n",
            "[239 epoch] tr_loss: 1.6483  val_loss: 1.6218  pre_mean val_loss:  1.6730  early stopping ccount:  0\n",
            "[240 epoch] tr_loss: 1.6508  val_loss: 1.6248  pre_mean val_loss:  1.6718  early stopping ccount:  0\n",
            "[241 epoch] tr_loss: 1.6485  val_loss: 1.6189  pre_mean val_loss:  1.6686  early stopping ccount:  0\n",
            "[242 epoch] tr_loss: 1.6496  val_loss: 1.6982  pre_mean val_loss:  1.6659  early stopping ccount:  1\n",
            "[243 epoch] tr_loss: 1.6470  val_loss: 1.5584  pre_mean val_loss:  1.6647  early stopping ccount:  0\n",
            "[244 epoch] tr_loss: 1.6465  val_loss: 1.6732  pre_mean val_loss:  1.6646  early stopping ccount:  1\n",
            "[245 epoch] tr_loss: 1.6492  val_loss: 1.5931  pre_mean val_loss:  1.6579  early stopping ccount:  0\n",
            "[246 epoch] tr_loss: 1.6451  val_loss: 1.6192  pre_mean val_loss:  1.6524  early stopping ccount:  0\n",
            "[247 epoch] tr_loss: 1.6443  val_loss: 1.6453  pre_mean val_loss:  1.6551  early stopping ccount:  0\n",
            "[248 epoch] tr_loss: 1.6481  val_loss: 1.5897  pre_mean val_loss:  1.6524  early stopping ccount:  0\n",
            "[249 epoch] tr_loss: 1.6464  val_loss: 1.7271  pre_mean val_loss:  1.6513  early stopping ccount:  1\n",
            "[250 epoch] tr_loss: 1.6436  val_loss: 1.5445  pre_mean val_loss:  1.6463  early stopping ccount:  0\n",
            "[251 epoch] tr_loss: 1.6427  val_loss: 1.6027  pre_mean val_loss:  1.6455  early stopping ccount:  0\n",
            "[252 epoch] tr_loss: 1.6433  val_loss: 1.6574  pre_mean val_loss:  1.6419  early stopping ccount:  1\n",
            "[253 epoch] tr_loss: 1.6458  val_loss: 1.6529  pre_mean val_loss:  1.6404  early stopping ccount:  2\n",
            "[254 epoch] tr_loss: 1.6457  val_loss: 1.6819  pre_mean val_loss:  1.6421  early stopping ccount:  3\n",
            "[255 epoch] tr_loss: 1.6397  val_loss: 1.6344  pre_mean val_loss:  1.6360  early stopping ccount:  0\n",
            "[256 epoch] tr_loss: 1.6429  val_loss: 1.6825  pre_mean val_loss:  1.6377  early stopping ccount:  1\n",
            "[257 epoch] tr_loss: 1.6418  val_loss: 1.5893  pre_mean val_loss:  1.6312  early stopping ccount:  0\n",
            "[258 epoch] tr_loss: 1.6397  val_loss: 1.6075  pre_mean val_loss:  1.6311  early stopping ccount:  0\n",
            "[259 epoch] tr_loss: 1.6392  val_loss: 1.6070  pre_mean val_loss:  1.6304  early stopping ccount:  0\n",
            "[260 epoch] tr_loss: 1.6385  val_loss: 1.5583  pre_mean val_loss:  1.6271  early stopping ccount:  0\n",
            "[261 epoch] tr_loss: 1.6386  val_loss: 1.5906  pre_mean val_loss:  1.6257  early stopping ccount:  0\n",
            "[262 epoch] tr_loss: 1.6375  val_loss: 1.6319  pre_mean val_loss:  1.6224  early stopping ccount:  1\n",
            "[263 epoch] tr_loss: 1.6365  val_loss: 1.6196  pre_mean val_loss:  1.6254  early stopping ccount:  0\n",
            "[264 epoch] tr_loss: 1.6427  val_loss: 1.6988  pre_mean val_loss:  1.6267  early stopping ccount:  1\n",
            "[265 epoch] tr_loss: 1.6381  val_loss: 1.6851  pre_mean val_loss:  1.6313  early stopping ccount:  2\n",
            "[266 epoch] tr_loss: 1.6396  val_loss: 1.7340  pre_mean val_loss:  1.6370  early stopping ccount:  3\n",
            "[267 epoch] tr_loss: 1.6418  val_loss: 1.7097  pre_mean val_loss:  1.6402  early stopping ccount:  4\n",
            "early stopping\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLX9MeWXmbJp",
        "colab_type": "text"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uy7RmwD274-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "919697a8-eb4a-482e-d032-4d84fddefc55"
      },
      "source": [
        "# from Jeongho_Kim's HW2\n",
        "# : https://github.com/cutz-j/Deeplearning/blob/master/hw2/%5BJeongho_Kim%5DCIFAR_10.ipynb\n",
        "def top5acc(y_pred, y_val):\n",
        "    np_y_pred = y_pred.cpu().numpy()\n",
        "    np_y_val = y_val.cpu().numpy()\n",
        "    correct = 0\n",
        "    for i in range(np_y_pred.shape[0]):\n",
        "        if np_y_val[i] in np.argsort(np_y_pred[i])[-5:]:\n",
        "            correct +=1 \n",
        "    return correct\n",
        "\n",
        "\n",
        "total = 0\n",
        "correct_1 = 0\n",
        "correct_5 = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for i, (inputs, labels) in enumerate(test_dataloader, 0):\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        _, predicted_1 = torch.max(outputs.data, 1)\n",
        "        # _, predicted_5 = torch.topk(outputs.data, 5)\n",
        "        # _, predicted_5 = torch.max(outputs.data, 5)\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct_1 += (labels.data == predicted_1).sum().item()\n",
        "        correct_5 += top5acc(outputs.data, labels.data)\n",
        "        \n",
        "print('top1 accuracy: {:.1f}'.format(correct_1/total*100))\n",
        "print('top5 accuracy: {:.1f}'.format(correct_5/total*100))"
      ],
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "top1 accuracy: 65.3\n",
            "top5 accuracy: 95.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b13FT6Ph3vM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}